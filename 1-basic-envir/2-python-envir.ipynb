{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python环境配置\n",
    "\n",
    "本文的内容框架主要参考了[Setting Up a Python Development Environment with and without Docker](https://nickjanetakis.com/blog/setting-up-a-python-development-environment-with-and-without-docker)，后面每节又各有参考（详见下文）。\n",
    "\n",
    "写程序一个很重要的内容就是 setting up your computer 。什么意思呢？总的来说，包括以下几个部分：\n",
    "\n",
    "1. What code editor should I use? 用什么编辑器\n",
    "2. How do I install Python? 如何安装Python\n",
    "3. How do I install my app’s dependencies? 如何安装程序依赖包 （如果不用docker基本上看到这小节的前半部分就够了）\n",
    "4. How do I install required external services? 如何安装必须的外部服务\n",
    "5. How do I run my application? 如何运行自己的程序\n",
    "\n",
    "## What Code Editor Should I Use?\n",
    "\n",
    "python中比较常用的IDE有pycharm和vscode，随意选择，都可以。\n",
    "\n",
    "这里推荐pycharm，windows下安装的话可以直接百度，应较容易。\n",
    "\n",
    "Ubuntu下可以使用这个链接: https://www.jetbrains.com/pycharm/download/download-thanks.html?platform=linux 下载安装包。\n",
    "\n",
    "然后解压文件：\n",
    "\n",
    "```Shell\n",
    "tar -xzf pycharm-professional-2019.3.1.tar.gz\n",
    "```\n",
    "\n",
    "使用tar -xzf pycharm-professional-2019.3.1.tar.gz -C <指定文件夹> 可以解压到指定文件夹下，当然也可以解压后再移动到指定文件夹下，比如：\n",
    "\n",
    "```Shell\n",
    "mv pycharm-2019.3.1 ../programs/pycharm-2019.3.1\n",
    "```\n",
    "\n",
    "然后可以进入文件夹打开软件了：\n",
    "\n",
    "```Shell\n",
    "cd ../programs/pycharm-2019.3.1\n",
    "cd bin\n",
    "sh pycharm.sh\n",
    "```\n",
    "\n",
    "这时候稍等一会儿，会弹出pycharm的界面。可以一直默认。然后如果是专业版，需要激活，可以使用学生账号来激活，这是免费的。激活后就可以使用了。\n",
    "\n",
    "如果想让pycharm后台运行，那么可以执行下列代码：\n",
    "\n",
    "```Shell\n",
    "sh pycharm.sh &\n",
    "```\n",
    "\n",
    "然后在命令行敲回车，就可以打开新的对话了。\n",
    "\n",
    "如果不想要.Pycharmxxx 系统配置文件在默认文件夹下，那么可以参考：[PyCharm 占用过大 C 盘空间，system 配置文件迁移](https://www.cnblogs.com/jingsupo/p/11616205.html) 配置。\n",
    "\n",
    "首先，先将你的.PyCharm2018.3文件复制到你想放的文件夹下。\n",
    "\n",
    "然后利用PyCharm 里的 Help/Edit Custom Properties 的选项新建 idea.properties 文件\n",
    "\n",
    "之后在创建的文件夹下进行如下修改，当然除了 system 之外，还可以配置其他路径将其他内容也进行迁移。\n",
    "\n",
    "``` config\n",
    "# custom PyCharm properties\n",
    "\n",
    "idea.config.path=${user.home}/.PyCharm2018.3/config\n",
    "idea.system.path=${user.home}/.PyCharm2018.3/system\n",
    "# idea.plugins.path=${idea.config.path}/plugins\n",
    "# idea.log.path=${idea.system.path}/log\n",
    "```\n",
    "\n",
    "比如我的是：idea.config.path=/mnt/sdc/wvo5024/.PyCharm2019.3/config\n",
    "\n",
    "然后将原文件夹下的system文件夹删除即可，注意不要删除config文件夹，因为这个idea.properties 文件就在这个文件夹下。\n",
    "\n",
    "## Install Python\n",
    "\n",
    "首先安装python，个人建议直接安装anaconda，上一小节已经说过了，所以到这里的话应该已经安装过了。\n",
    "\n",
    "这里简单补充下pip和conda的相关概念。主要参考了anaconda的blog：[Understanding Conda and Pip](https://www.anaconda.com/understanding-conda-and-pip/)\n",
    "\n",
    "conda 和 pip 通常被认为是差不多的。然而虽然它们很多功能重叠，但它们被设计是用于不同的目的地。\n",
    "\n",
    "Pip 是一个python包官方推荐的从[Python Package Index, PyPI](https://pypi.org/)安装包的工具。Pip 以wheels或source distributions的形式安装 打包的python 软件。从源码安装，即后者source distribution需要系统有兼容的解释器和需要的库。\n",
    "\n",
    "Conda是一个跨平台的包和环境管理器，它是从Anaconda repository 和 anaconda cloud 安装和管理conda 包。conda包是二进制包，所以不需要解释器来安装，并且conda安装的不仅限于python软件，也可以是C或者C++库，或者R包等。\n",
    "\n",
    "这就是两者的一个主要区别，即pip安装python包，而conda安装任何语言的包。在使用pip之前，必须要安装有python解释器。而conda不仅可以安装python包，还可以安装python解释器。\n",
    "\n",
    "两者的另一个区别是conda能创建独立的环境，在各独立环境中，可以安装各自的python版本和包。这在数据科学工具中很有用，因为不同工具的依赖可能会有冲突。而pip需要依赖于一些工具来创建独立环境，比如virtualenv或venv。还有一些像pipenv，poetry和hatch的工具，它们包装了pip和virtualenv来提供简易的使用方法。\n",
    "\n",
    "pip和conda在安装依赖时也有不同。安装包时，pip安装以递归序列的循环来安装依赖包，不能保证同时满足所有依赖包的安装。如果按顺序较早安装的包与按顺序较晚安装的包有不兼容的依赖项版本，则可能导致环境以微妙的方式被破坏。而conda使用了可满足性(SAT)求解器来验证安装在环境中的所有包的所有要求都能得到满足。这个check会花费一些时间，但是能防止出现错误的安装。只要包元数据关于依赖的内容是正确的，conda就能产出正确的工作环境。\n",
    "\n",
    "用conda可以安装的包 有 anaconda repo里超过1500个库以及anaconda cloud中的可以从包括 conda-forge 和 bioconda 等通道处获取的数千个包。conda有很多不同的通道，什么意思呢？这里简单补充下，根据[conda-forge 的 introduction](https://conda-forge.org/docs/user/introduction.html)，conda团队打包了很多包并以默认channel的形式提供给所有的用户。但是如果想要使用的包不在默认通道中，用户就要创建自己的channel，而这时候找包，用不同channel包能兼容，channel一直有维护等都难做到，但conda-forge是一个专用通道，它能帮助轻松解决这些问题。\n",
    "\n",
    "尽管conda中可以有这么多的工具包可用，但是相比于PyPI上的超过15万可用包而言仍然是很小的。如果有些工具包只能通过pip来安装，考虑到conda和pip的相似性，混合使用这两种工具来创建计算环境也不奇怪了。一个表格简单总结下conda和pip的比较：\n",
    "\n",
    "| |conda|pip|\n",
    "|-|-|-|\n",
    "|manages |binaries|wheel or source|\n",
    "|can require compilers|no|yes|\n",
    "|package types|any|Python-only|\n",
    "|create environment|yes, built-in|no, requires virtualenv or venv|\n",
    "|dependency checks|yes|no|\n",
    "|package sources|Anaconda repo and cloud|PyPI|\n",
    "\n",
    "## Getting Your Python App Running without Docker\n",
    "\n",
    "关于docker是什么可以暂时不用管，因为这一节是不会用到它的。\n",
    "\n",
    "接下来，就是如何安装所需程序包。比如numpy，pandas等，也有 required external services 比如你的数据库。\n",
    "\n",
    "先说如何安装依赖工具包。当然你可以使用pip或者conda一个个地安装，如果你已经装了很多库，想要更新，可以使用如下代码更新pip安装的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pip批量更新\n",
    "import pip\n",
    "from subprocess import call\n",
    "from pip._internal.utils.misc import get_installed_distributions\n",
    "\n",
    "n = 1\n",
    "s = len(get_installed_distributions())\n",
    "for dist in get_installed_distributions():\n",
    "    call(\"pip install --upgrade \" + dist.project_name, shell=True)\n",
    "    print(\"共有{}个库,正在更新第{}个库,请耐心等待.......\".format(s, n))\n",
    "    n += 1\n",
    "print(\"{}个库全部更新完毕\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个一个地安装显然是比较慢的，最关键的是，可能会有两个不同项目使用同一个包不同版本的情况，那就很麻烦了。所以就有人开发了一个叫做 Virtual Environment 的东西--Virtualenv，这个python工具可以为每个项目创建一个虚拟环境，这样项目互相之间就不会影响了。接下来记录下Virtual Environment及其相关的内容。因为conda和pip的方式不同，所以下面分开记录，个人根据自己的情况自己选择工具，各有优劣，比如对于conda，因为是跨语言的，所以有些外部依赖可以容易安装，但是会有很多python包不在conda中，需要混合使用pip。而虚拟环境或者直接使用pipenv就能随意安装python包，但是它的问题是有可能有些外部依赖会导致python包不能安装成功，这对于经常需要一些外部依赖的水文水资源相关计算来说确实不是很方便，另外有时候会有一些可以用pip而不能用pipenv安装的包，也会造成一些不方便。个人建议可以先使用conda，毕竟安装python的时候，我们都是从anaconda安装开始的。更多建议可以参考：[Conda: Myths and Misconceptions](https://jakevdp.github.io/blog/2016/08/25/conda-myths-and-misconceptions/)\n",
    "\n",
    "### Conda Environment\n",
    "\n",
    "本小节先简单介绍下conda的使用的一些意见，尤其是和pip混合使用时要注意的内容，然后再看看具体如何用conda管理environment。\n",
    "\n",
    "根据前面第二节的介绍可以看出，根据anaconda的意见，是能用conda就用conda，不够的时候再用pip。关于在conda中使用pip，再补充一些内容，参考：[Using Pip in a Conda Environment](https://www.anaconda.com/using-pip-in-a-conda-environment/)\n",
    "\n",
    "混合使用conda和pip有时候会遇到一些问题，这是因为conda不会控制它不安装的包，如果conda 在pip之后安装，可能会overwrite一些包，这可能会破坏pip安装的内容。类似的pip也会破坏conda的。有一些方式可以避免在同时使用conda和pip时遇到环境被破坏的情况。\n",
    "\n",
    "一种就是只用conda，如果需要的软件不是作为conda包提供的，那么可以使用conda build为上述软件创建包。对于PyPI上可用的项目，conda skeleton命令(它是conda-build的一部分)经常生成一个配方，可以使用该配方创建一个conda包，而几乎不需要修改。\n",
    "\n",
    "为所有需要的附加软件创建conda包是将数据科学环境放在一起的一种可靠的安全方法，但如果环境中包含大量仅在PyPI上可用的包，则可能成为一种负担。在这些情况下，仅在通过conda安装了所有其他需求之后才使用pip是最安全的做法。此外，应该使用“仅在需要时才升级策略”的参数来运行pip，以防止对通过conda安装的包进行不必要地升级。这是运行pip时的默认值，但是不应该更改它。\n",
    "\n",
    "如果希望使用pip与conda包一起安装软件，那么最好将此安装安装到专门构建的conda环境中，以保护其他环境不受pip可能进行的任何修改的影响。Conda环境彼此隔离，允许安装不同版本的包。在conda环境中，尽可能使用硬链接，而不是复制文件来节省空间。如果安装了一组类似的包，那么每个新的conda环境只需要少量的额外磁盘空间。许多用户仅依赖于通过安装Anaconda或Miniconda创建的根conda环境。如果这个环境充斥着pip和conda安装，那么恢复起来就会困难得多。另一方面，创建独立的conda环境允许您轻松地删除和重新创建环境，而不会危及您的核心conda功能。\n",
    "\n",
    "一旦使用pip将软件安装到conda环境中，conda将不知道这些更改，并可能进行破坏环境的修改。与先运行conda、pip再运行conda不同，更可靠的方法是使用合并后的conda需求创建一个新环境，然后运行pip。可以在删除旧环境之前测试这个新环境。再次强调，造成问题的主要是pip的状态性。由于**安装包的顺序而存在的状态越多，就越难以保持正常工作**。\n",
    "\n",
    "对于经常重新创建的环境，将conda和pip包需求存储在文本文件中是一个很好的实践。包需求可以通过文件参数提供给conda，通过-r或需求提供给pip。可以将包含conda和pip需求的单个文件导出或提供给conda env命令来控制环境。这两种方法的优点是，描述环境的文件可以检入版本控制系统并与他人共享。\n",
    "\n",
    "总之，在结合使用conda和pip时，最好使用一个隔离的conda环境。只有在使用conda来安装尽可能多的包之后，才能使用pip来安装任何剩余的软件。如果需要对环境进行修改，最好创建一个新环境，而不是在pip之后运行conda。在适当的时候，conda和pip需求应该存储在文本文件中。\n",
    "\n",
    "总结下，就是：\n",
    "\n",
    "- Use pip only after conda\n",
    "    - install as many requirements as possible with conda, then use pip\n",
    "    - pip should be run with –upgrade-strategy only-if-needed (the default)\n",
    "    - Do not use pip with the –user argument, avoid all “users” installs\n",
    "- Use conda environments for isolation\n",
    "    - create a conda environment to isolate any changes pip makes\n",
    "    - environments take up little space thanks to hard links\n",
    "    - care should be taken to avoid running pip in the “root” environment\n",
    "- Recreate the environment if changes are needed\n",
    "    - once pip has been used conda will be unaware of the changes\n",
    "    - to install additional conda packages it is best to recreate the environment\n",
    "- Store conda and pip requirements in text files\n",
    "    - package requirements can be passed to conda via the –file argument\n",
    "    - pip accepts a list of Python packages with -r or –requirements\n",
    "    - conda env will export or create environments based on a file with conda and pip requirements\n",
    "\n",
    "了解了以上概念，现在根据conda官方文档[Managing environments](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)，看看如何管理环境。\n",
    "\n",
    "接下来就以为本项目创建环境为例。**下面代码中为本项目实际使用的会用 “\\$” 标出，注意如果你在使用本项目代码，不要一步步照做，只需要执行“\\$” 标出的代码即可**。\n",
    "\n",
    "在本项目文件夹下打开terminal，输入：\n",
    "\n",
    "```Shell\n",
    "conda create --name hydrus\n",
    "```\n",
    "\n",
    "输入y即可创建。创建的环境存储在 anaconda3\\envs 文件夹下。如果没有指定python环境，那么默认的使用的和安装的anaconda一样的python版本，这里指定使用的是python3.7。要创建一个特定的python版本环境可以使用如下代码：\n",
    "\n",
    "```Shell\n",
    "$ conda create --name hydrus python=3.7\n",
    "```\n",
    "\n",
    "根据提示可以看到执行以下语句可进入hydrus环境：\n",
    "\n",
    "```Shell\n",
    "$ conda activate hydrus\n",
    "```\n",
    "\n",
    "如果你没能进入，那可能是terminal环境有点问题，如果你是windows那就重新打开终端试试，如果是Ubuntu，那么就重新加载下.bashrc文件。\n",
    "\n",
    "进入hydrus环境后，执行以下语句可以退出hydrus环境。\n",
    "\n",
    "```Shell\n",
    "conda deactivate\n",
    "```\n",
    "\n",
    "还可以指定environment的安装环境，比如下列命令会在当前目录下创建一个叫做envs的子文件夹：\n",
    "\n",
    "```Shell\n",
    "conda create --prefix ./envs\n",
    "```\n",
    "\n",
    "这时候进入环境的命令需要使用全名（安装后会有提示），比如我在Ubuntu下为一个项目建立了独立环境：\n",
    "\n",
    "```Shell\n",
    "conda activate /mnt/sdc/wvo5024/hydro-anthropogenic-lstm/envs\n",
    "```\n",
    "\n",
    "这在需要单独为一个项目创建单独的环境时尤其有用。如果不想要这么长的前缀，那么可以执行以下语句修改.condarx 文件内容：\n",
    "\n",
    "```Shell\n",
    "conda config --set env_prompt '({name})'\n",
    "```\n",
    "\n",
    "如果已经有.condarc文件，就会修改，如果没有，该命令会创建一个.condarc文件。\n",
    "\n",
    "根据官方文档介绍，.condarx这个文件在以下地址中的一个里：\n",
    "\n",
    "```Shell\n",
    "if on_win:\n",
    " SEARCH_PATH = (\n",
    "     'C:/ProgramData/conda/.condarc',\n",
    "     'C:/ProgramData/conda/condarc',\n",
    "     'C:/ProgramData/conda/condarc.d',\n",
    " )\n",
    " else:\n",
    " SEARCH_PATH = (\n",
    "     '/etc/conda/.condarc',\n",
    "     '/etc/conda/condarc',\n",
    "     '/etc/conda/condarc.d/',\n",
    "     '/var/lib/conda/.condarc',\n",
    "     '/var/lib/conda/condarc',\n",
    "     '/var/lib/conda/condarc.d/',\n",
    "  )\n",
    "\n",
    " SEARCH_PATH += (\n",
    "     '$CONDA_ROOT/.condarc',\n",
    "     '$CONDA_ROOT/condarc',\n",
    "     '$CONDA_ROOT/condarc.d/',\n",
    "     '~/.conda/.condarc',\n",
    "     '~/.conda/condarc',\n",
    "     '~/.conda/condarc.d/',\n",
    "     '~/.condarc',\n",
    "     '$CONDA_PREFIX/.condarc',\n",
    "     '$CONDA_PREFIX/condarc',\n",
    "     '$CONDA_PREFIX/condarc.d/',\n",
    "     '$CONDARC',\n",
    " )\n",
    "```\n",
    "\n",
    "比如我的Ubuntu系统下，就在/home/wvo5024，即用户主文件夹下。现在再进入到刚才创建的环境里，可以看到前缀会变成简单的 envs 。 本项目就暂时不用这个了，仍然直接创建 hydrus 环境。激活hydrus环境后，就可以进入jupyter lab了。注意，如果直接进入cmd，输入jupyter lab，那么进入的还是外边安装的anaconda的jupyter lab，所以这里要稍微调整下。\n",
    "\n",
    "首先，在hydrus环境下安装jupyter lab：\n",
    "\n",
    "```Shell\n",
    "$ conda install -c conda-forge jupyterlab\n",
    "```\n",
    "\n",
    "然后再执行：\n",
    "\n",
    "```Shell\n",
    "$ jupyter lab\n",
    "```\n",
    "\n",
    "现在可以在命令行里看到：\n",
    "\n",
    "![](Picture3.png)\n",
    "\n",
    "可以看到启动的jupyter lab是hydrus环境下的，接下来就可以在jupyter lab中操作了，jupyter lab 导航页面如下所示：\n",
    "\n",
    "![](Picture2.png)\n",
    "\n",
    "可以看到，能打开终端，能新建notebook，txt文件等。以下没有特别说明，终端操作都是在jupyter lab中打开的终端上进行，打开一个终端，输入：\n",
    "\n",
    "```Shell\n",
    "$ conda env list\n",
    "```\n",
    "\n",
    "可以看到已经处于hydrus环境下了。\n",
    "\n",
    "接下来可以使用代码安装package，比如\n",
    "\n",
    "```Shell\n",
    "conda install -n hydrus scipy\n",
    "```\n",
    "\n",
    "如果需要指定版本，可以使用如下语句：\n",
    "\n",
    "```Shell\n",
    "conda install -n hydrus scipy=0.15.0\n",
    "```\n",
    "\n",
    "如果在创建环境时，就指定安装包，可以使用类似如下语句：\n",
    "\n",
    "```Shell\n",
    "conda create -n hydrus python=3.6 scipy=0.15.0 astroid babel\n",
    "```\n",
    "\n",
    "也可以通过environment.yml文件来创建环境。手动创建文件的方式可以参考：[Creating an environment file manually](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#create-env-file-manually)\n",
    "\n",
    "示例可直接看本项目的environment.yml文件。可以先删除刚刚创建的虚拟环境：\n",
    "\n",
    "```Shell\n",
    "conda remove --name hydrus --all\n",
    "```\n",
    "\n",
    "如果是删除./envs文件夹，可以直接手动删除即可。\n",
    "\n",
    "然后在项目文件夹下执行以下语句就可以创建环境hydrus了，直接使用下列语句：\n",
    "\n",
    "```Shell\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "进入虚拟环境并查看当前环境是否安装正确：\n",
    "\n",
    "```Shell\n",
    "conda activate hydrus\n",
    "conda env list\n",
    "```\n",
    "\n",
    "如果更改了environment.yml文件的内容后需要更新环境，则可以运行：\n",
    "\n",
    "```Shell\n",
    "conda env update --file environment.yml  --prune\n",
    "```\n",
    "\n",
    "--prune参数表示删除不再需要的依赖包。\n",
    " \n",
    "如果需要复制环境，则可以使用：\n",
    " \n",
    "```Shell\n",
    "conda create --name hydrus-clone --clone hydrus\n",
    "```\n",
    "\n",
    "如果在conda中使用pip，首先在conda中安装pip：\n",
    "\n",
    "```Shell\n",
    "conda install -n hydrus pip\n",
    "conda activate hydrus\n",
    "```\n",
    "\n",
    "然后就可以使用pip了。比如安装 matplotlib：\n",
    "\n",
    "```Shell\n",
    "pip install matplotlib\n",
    "```\n",
    "\n",
    "除了前面说的手动写yml文件，还可以直接使用conda导出。在hydrus环境下，使用下列代码可以生成新的environment.yml文件：\n",
    "\n",
    "```Shell\n",
    "$ conda env export > environment.yml\n",
    "```\n",
    "\n",
    "环境会同时导出conda和pip安装的包（如果pip安装了包）。\n",
    "\n",
    "接下来看看在hydrus环境中使用conda-forge会有什么。这里建议直接看看earthlab的github项目：[earth-analytics-python-env](https://github.com/earthlab/earth-analytics-python-env)的environment.yml文件，就知道了，对应的博客：[Lesson 4. Set Up Your Conda Earth Analytics Python Environment Setup earth analytics environment](https://www.earthdatascience.org/workshops/setup-earth-analytics-python/setup-python-conda-earth-analytics-environment/)\n",
    "\n",
    "这里试用conda-forge在hydrus环境里安装一个包，然后更新environmetn.yml文件，看看会发生什么。\n",
    "\n",
    "```Shell\n",
    "conda install -c conda-forge cartopy\n",
    "# 直接导出就会覆盖之前的yml文件了\n",
    "conda env export > environment.yml\n",
    "```\n",
    "\n",
    "查看environment.yml文件可以看到在channels下多了conda-forge。注意根据[conda-forge Tips & tricks](https://conda-forge.org/docs/user/tipsandtricks.html#how-to-fix-it) 的说明，conda-forge和conda并不完全兼容，因此有时候，**需要将前后顺序钉死，conda-forge在前**，这样才能避免出现安装错误，比如安装常用gis库 geopandas时，就必须得这么做，否则很可能报错。.condarc 文件内容如下：\n",
    "\n",
    "``` code\n",
    "channel_priority: strict\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "```\n",
    "\n",
    "按照前面说的.condarc文件的位置寻找它，找到后，把channels的内容添加进去，如果没有找到，说明还没有该文件，那么执行以下语句，系统会自动为你创建一个：\n",
    "\n",
    "```Shell\n",
    "$ conda config --add channels conda-forge\n",
    "```\n",
    "\n",
    "现在再去找找，就可以发现.condarc文件了，比如在我的win10上，是在 C:\\Users\\wvo5024 ，即用户的主目录下，打开该文件，然后将上面的 channel_priority: strict 添加进去，并保存。\n",
    "\n",
    "然后在终端执行以下语句固定顺序：\n",
    "\n",
    "```Shell\n",
    "$ conda config --set channel_priority strict\n",
    "```\n",
    "\n",
    "最后导出environment.yml，可以用文本编辑器打开它，看看其中都有什么内容。\n",
    "\n",
    "```Shell\n",
    "$ conda env export > environment.yml\n",
    "```\n",
    "\n",
    "**如果不需要用docker，也不用pip的environment，到这里就够了，不必再往下看了，下面都是针对实际项目中使用pipenv及docker的。**\n",
    "\n",
    "进入下一节：[1-learn-python/1.1-basic-python.ipynb](https://github.com/OuyangWenyu/hydrus/blob/master/1-learn-python/1.1-basic-python.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Environment 和 Pipenv\n",
    "\n",
    "在开发Python应用程序的时候，系统安装的Python3只有一个版本。所有第三方的包都会被pip安装到Python3的site-packages目录下。\n",
    "\n",
    "如果我们要同时开发多个应用程序，那这些应用程序都会共用一个Python，就是安装在系统的Python 3。如果应用A需要ruanjian 2.7，而应用B需要ruanjian 2.6怎么办？\n",
    "\n",
    "这种情况下，**每个应用可能需要各自拥有一套“独立”的Python运行环境**。**virtualenv**就是用来为一个应用**创建一套“隔离”的Python运行环境**。\n",
    "\n",
    "首先，我们用pip安装virtualenv：\n",
    "\n",
    "``` bash\n",
    "pip install virtualenv\n",
    "```\n",
    "\n",
    "然后，假定我们要开发一个新的项目，需要一套独立的Python运行环境，可以这么做：\n",
    "\n",
    "第一步，创建目录：\n",
    "\n",
    "```bash\n",
    "mkdir myproject\n",
    "cd myproject\n",
    "```\n",
    "\n",
    "第二步，创建一个独立的Python运行环境，命名为venv：\n",
    "\n",
    "```bash\n",
    "virtualenv --no-site-packages venv\n",
    "```\n",
    "\n",
    "如果需要指定python版本，那么执行：\n",
    "\n",
    "```Shell\n",
    "virtualenv --no-site-packages venv --python=python3.7\n",
    "```\n",
    "\n",
    "如果想要删除刚刚创建的虚拟环境，因为我们什么也没装，直接删除venv文件夹就行了。\n",
    "\n",
    "命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了**参数--no-site-packages**，这样，**已经安装到系统Python环境中的所有第三方包都不会复制过来**，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。\n",
    "\n",
    "新建的Python环境被放到当前目录下的venv目录。有了venv这个Python环境，可以用source进入该环境：\n",
    "\n",
    "```bash\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "可以观察命令行，注意到命令提示符变了，**有个(venv)前缀**，表示当前环境是一个名为venv的Python环境。\n",
    "\n",
    "然后可以正常安装各种第三方包，并运行python命令：\n",
    "\n",
    "``` bash\n",
    "pip install jinja2\n",
    "```\n",
    "\n",
    "在venv环境下，用pip安装的包都被安装到venv这个环境下，系统Python环境不受任何影响。也就是说，venv环境是专门针对myproject这个应用创建的。\n",
    "\n",
    "退出当前的venv环境，使用deactivate命令：\n",
    "\n",
    "```bash\n",
    "deactivate \n",
    "```\n",
    "\n",
    "此时就回到了正常的环境，现在pip或python均是在系统Python环境下执行。\n",
    "\n",
    "完全**可以针对每个应用创建独立的Python运行环境**，这样就可以对每个应用的Python环境进行隔离。\n",
    "\n",
    "virtualenv是如何创建“独立”的Python运行环境的呢？原理很简单，就是把系统Python复制一份到virtualenv的环境，用命令source venv/bin/activate进入一个virtualenv环境时，virtualenv会修改相关环境变量，让命令python和pip均指向当前的virtualenv环境。\n",
    "\n",
    "说道配置环境，就要提到requirements.txt，接下来的内容参考：[What is the python requirements.txt?](https://www.idkrtm.com/what-is-the-python-requirements-txt/)\n",
    "\n",
    "如果浏览github上的python项目，经常会看到它。它就是一个指定运行项目所需的python packages 的。一般是在项目根目录下。一个requirements.txt形如：\n",
    "\n",
    "pyOpenSSL==0.13.1\n",
    "\n",
    "pyparsing==2.0.1\n",
    "\n",
    "python-dateutil==1.5\n",
    "\n",
    "每行对应一个package，然后是它的版本号。版本号也很重要，毕竟版本变化之后，容易出bug。\n",
    "\n",
    "现在考虑一个问题，如果有了requirements.txt，如何安装对应库。首先，看看freeze。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过freeze可以看到已经安装的所有库以及其版本。可以将这些全部拷贝，然后创建一个requirements.txt，放于其中。可以检查下，把自己用不到的库去掉。\n",
    "\n",
    "接下来看看如何根据requirements.txt安装库。\n",
    "\n",
    "1. 打开终端\n",
    "2. 进入 requirements.txt 所在的文件夹\n",
    "3. 运行： pip install -r requirements.txt\n",
    "\n",
    "以上在virtual environment中执行上述操作更好。\n",
    "\n",
    "前面提到了pip和virtualenv，其实还有一个更强大的工具pipenv，接下来就记录下其基本内容。本节参考了：[pipenv使用指南](https://crazygit.wiseturtles.com/2018/01/08/pipenv-tour/)，[Pipenv: A Guide to the New Python Packaging Tool](https://realpython.com/pipenv-guide/) 以及 [Pipenv——最好用的python虚拟环境和包管理工具](https://www.cnblogs.com/zingp/p/8525138.html)等。\n",
    "\n",
    "首先，简单概述下，pipenv是**Python官方推荐的包管理工具**。可以说，它**集成了virtualenv, pip和pyenv三者的功能**。其目的旨在集合了所有的包管理工具的长处，如: npm, yarn, composer等的优点。\n",
    "\n",
    "它能够**自动为项目创建和管理虚拟环境**，从Pipfile文件添加或删除安装的包，同时生成Pipfile.lock来锁定安装包的版本和依赖信息，避免构建错误。\n",
    "\n",
    "pipenv主要解决了如下问题:\n",
    "\n",
    "- 不用再单独使用**pip和virtualenv**, 现在它们**合并**在一起了\n",
    "- **不用再维护requirements.txt**, 使用**Pipfile和Pipfile.lock**来代替\n",
    "- 可以使用多个python版本(python2和python3)\n",
    "- 在安装了pyenv的条件下，可以自动安装需要的Python版本\n",
    "\n",
    "接下来，看看pipenv的来龙去脉。首先明确pipenv解决了什么问题？\n",
    "\n",
    "#### Problems that Pipenv Solves\n",
    "\n",
    "从上面说到的requirements.txt说起，比如在requirements中有flask==0.12.1，虽然指定了flask的版本，但是flask的依赖的版本是没有指定的，如果直接使用上一节说到的pip install安装的话，都会安装最新版的依赖。这可能会导致一些小问题。这就是real issue：**the build isn’t deterministic**。 即给定相同的requirements.txt文件，安装的库却可能是不同的。\n",
    "\n",
    "比较常用的解决方法是上一节也提到过的freeze，这样就能获取所有的库及其版本号。执行之后，将结果copy到requirements.txt即可。然而，这个方法却有另外的问题。\n",
    "\n",
    "因为，旧版本可能会有bug，有可能某个版本的依赖是需要及时更新补丁的，如果用了freeze的办法得到requirements文件，现在就需要手动修改一下某个依赖库。实际上，很多时候也并不需要一直保持在现有的版本下，很多依赖库使用最新版本可能更好更安全。这一部分的问题就是：**How do you allow for deterministic builds for your Python project without gaining the responsibility of updating versions of sub-dependencies?**\n",
    "\n",
    "答案就是Pipenv。\n",
    "\n",
    "现在再看另一个问题。当处理多个项目时，如果项目A需要django 1.9版本，另一个项目B需要django 1.10版本。那么这时候就需要使用前面提到的 virtual environment 来处理。工具就是venv 。现在Pipenv是包含了venv 的功能的。\n",
    "\n",
    "然后还有一个Dependency Resolution。什么意思？加入 requirements.txt 文件中有如下代码：\n",
    "\n",
    "```python requirements\n",
    "package_a\n",
    "package_b\n",
    "```\n",
    "\n",
    "假如package_a有依赖 package_c>=1.0，而package_b 有依赖 package_c<=2.0. 那么现在就是要求package_c (being >=1.0 and <=2.0) 。现在想要工具自动选择一个合适的版本，这就是“dependency resolution.”现在如果在requirements文件中加入下列语句：\n",
    "\n",
    "```python requirements\n",
    "package_c>=1.0,<=2.0\n",
    "package_a\n",
    "package_b\n",
    "```\n",
    "\n",
    "不过如前所述，如果package_a改变了它的requirement，那么按照指定的requirements安装可能会出错。\n",
    "\n",
    "所以需要更加智能的安装工具，在不明确指定子依赖的情况下，能选择满足所有条件的库安装。\n",
    "\n",
    "#### Pipenv Introduction\n",
    "\n",
    "``` Shell\n",
    "pip install pipenv\n",
    "```\n",
    "\n",
    "安装了pipenv之后，就可以忘记pip了。因为它可以完全替代pip。它还会引入两个文件，一个Pipfile，替代requirements.txt，另一个是Pipfile.lock来执行deterministic builds。\n",
    "\n",
    "Pipenv整合了pip和virtualenv，可以让我们以简单的方式使用。\n",
    "\n",
    "比如创建一个virtual environment，在项目的根目录下，打开命令行，然后直接使用一下语句即可：\n",
    "\n",
    "```Shell\n",
    "pipenv shell\n",
    "```\n",
    "\n",
    "该语句会为该项目创建好一个同名虚拟环境，并在该项目文件夹下创建一个Pipfile文件，然后现在的命令行下已经处在该项目的虚拟环境下了。\n",
    "\n",
    "Pipfile是替代 requirements.txt 的。其语法是TOML的，关于TOML，可以参考：[TOML 教程 - 可能是目前最好的配置文件格式](https://zhuanlan.zhihu.com/p/50412485) ，总之是一个比较新的配置文件的格式。\n",
    "\n",
    "如果不小心创建错了，想要删除，则可以在同一个文件夹下执行下面语句：\n",
    "\n",
    "```Shell\n",
    "pipenv --rm\n",
    "```\n",
    "\n",
    "删除之后，Pipfile还在，如果不想要的话，手动删除即可。\n",
    "\n",
    "接下来就可以安装包了。首先可以看看虚拟环境下有什么包已经安装了：\n",
    "\n",
    "```Shell\n",
    "pipenv graph\n",
    "```\n",
    "\n",
    "上述语句可以查看所有包依赖情况。\n",
    "\n",
    "安装package语句类似如下形式：\n",
    "\n",
    "```Shell\n",
    "pipenv install numpy\n",
    "```\n",
    "\n",
    "一旦安装了一个package, pipenv就会再生成一个Pipfile.lock文件。\n",
    "\n",
    "Pipfile.lock是确保 deterministic builds 的，是一个JSON文件。其中有指定子依赖的版本。\n",
    "\n",
    "如果想要卸载安装的package，使用下面语句：\n",
    "\n",
    "```Shell\n",
    "pipenv uninstall numpy\n",
    "```\n",
    "\n",
    "卸载所有：\n",
    "\n",
    "```Shell\n",
    "pipenv uninstall --all\n",
    "```\n",
    "\n",
    "如果想要安装的是pytest，并且只想让它在测试开发的时候才用，生产时候不适用，可以加上--dev参数：\n",
    "\n",
    "```Shell\n",
    " pipenv install pytest --dev\n",
    "```\n",
    "\n",
    "如果想要将库推到生产环境下，需要锁定下安装环境：\n",
    "\n",
    "```Shell\n",
    "pipenv lock\n",
    "```\n",
    "\n",
    "这样，Pipfile.lock就不要再手动修改了。以上就是利用pipenv的一些基本操作。\n",
    "\n",
    "查看有哪些虚拟环境，对应项目在哪，可以使用下列语句：\n",
    "\n",
    "```Shell\n",
    "pipenv --venv\n",
    "pipenv --where\n",
    "```\n",
    "\n",
    "退出当前的虚拟环境直接使用：\n",
    "\n",
    "```Shell\n",
    "deactivate\n",
    "```\n",
    "\n",
    "如果想重新进入某个虚拟环境，可以用pipenv --venv找到该环境，比如/home/owen/.local/share/virtualenvs/hydrus--ORegRFb，然后使用类似如下代码即可：\n",
    "\n",
    "```Shell\n",
    ". /home/owen/.local/share/virtualenvs/hydrus--ORegRFb/bin/activate\n",
    "```\n",
    "\n",
    "如果不需要将自己的项目打包发布，那么到这就ok了。\n",
    "\n",
    "如果需要在IDE中配置虚拟环境，比如在Pycharm中配置，可以参考官网的步骤：[Pipenv environment](https://www.jetbrains.com/help/pycharm/pipenv.html)，但是我按照官方的没成功，因为没有.local/bin文件夹，这是因为我个人安装pipenv的时候，用的是anaconda下的pip，所以pipenv是安装在ananconda的文件夹下面了，在ananconda/bin文件夹下即可看到pipenv的可执行文件。\n",
    "\n",
    "注意首先在项目文件夹下创建虚拟环境（项目根目录下终端执行 pipenv shell），然后再到pycharm的该项目下，将pipenv添加到interpreter路径中。\n",
    "\n",
    "如果需要发布自己的项目，即做一个可以让别人import来使用的代码包，可以使用setup.py ，一般的工作流是这样的：\n",
    "\n",
    "- setup.py\n",
    "- install_requires keyword should include whatever the package “minimally needs to run correctly.”\n",
    "- Pipfile\n",
    "- Represents the concrete requirements for your package\n",
    "- Pull the minimally required dependencies from setup.py by installing your package using Pipenv:\n",
    "    - Use pipenv install '-e .'\n",
    "    - That will result in a line in your Pipfile that looks something like \"e1839a8\" = {path = \".\", editable = true}.\n",
    "- Pipfile.lock\n",
    "- Details for a reproducible environment generated from pipenv lock\n",
    "\n",
    "#### pipenv 基本使用\n",
    "\n",
    "这部分总结下前面introduction的内容，记录下如何生成pipfile和pipfile.lock，以及如何根据这些文件，快速在一个新环境下配置好依赖包。\n",
    "\n",
    "这部分参考了：[Pipenv一键搭建python虚拟环境](https://www.jianshu.com/p/1441169b3dbe).\n",
    "\n",
    "首先，安装pipenv。为了方便使用, 建议全局安装：\n",
    "\n",
    "```Shell\n",
    "pip install pipenv\n",
    "```\n",
    "\n",
    "进入你项目根目录文件夹，打开终端，执行：\n",
    "\n",
    "```Shell\n",
    "pipenv install\n",
    "```\n",
    "\n",
    "如果你已经有了pipfile和pipfile.lock文件，那么pipenv不仅会创建一个虚拟环境，还会安装pipfile.lock中的依赖包。如果没有，那pipenv会生成虚拟环境，并创建一个pipfile文件。\n",
    "\n",
    "然后你每次使用pipenv安装依赖的时候，pipfile都会自动更新。\n",
    "\n",
    "安装好你的依赖包，之后，使用：\n",
    "\n",
    "```Shell\n",
    "pipenv lock\n",
    "```\n",
    "\n",
    "就会生成你的pipfile.lock文件，这样你换到另一个环境下，也能很快地按照依赖包了。\n",
    "\n",
    "如果需要卸载虚拟环境，进入项目根目录，使用下述方式：\n",
    "\n",
    "```Shell\n",
    "pipenv --rm\n",
    "```\n",
    "\n",
    "### Installing external services\n",
    "\n",
    "前面说完了关于依赖包的安装，接着说说installing external services的事。\n",
    "\n",
    "如果你存储数据到数据库中了，那么数据库很可能会用到一些服务，比如MySQL，Postgres，Redis等。比如要用Postgres，那么你就要在电脑上安装它。还要注意由于你可能使用的操作系统不同，因此安装的情况也不一样。所以，要每个情况单独处理。\n",
    "\n",
    "安装好之后，就可以运行自己的代码程序了。如果你开发web服务端软件的话，你就知道有一些关于微服务的事，你可能有很多服务，管理这些服务还需要一些设置的，不知道就算了，不重要。\n",
    "\n",
    "总之，就是完成Installing external services前面的事情之后，还是有很多麻烦事。这也就是为什么要使用docker的motivation之一。\n",
    "\n",
    "## Getting Your Python App Running with Docker\n",
    "\n",
    "Docker的运用并不是一件容易的事情，所以不存在简单一两行代码就能解决上面说的所有事情的情况。不过如果理解docker是什么，这个过程还是相对简单的。\n",
    "\n",
    "使用docker就不需要担心项目隔离，因为Docker会为您处理这个问题。即用Python 2或3运行应用程序，每个应用程序有自己的依赖关系，这些都是是没有问题的，Virtualenv甚至不会被使用。\n",
    "\n",
    "另外，安装外部服务也很容易。你不会直接在你的主操作系统上安装它们。它们将在您的计算机上本地运行，但是它们将通过Docker运行。例如，启动和运行Postgres或Redis需要运行一个命令，不需要高级配置。\n",
    "\n",
    "还有最后,不需要使用很多各种devops工具,不需要担心外部服务运行时你不能开发你的应用程序,因为docker有自己的在几秒钟内用一个命令启动和关闭你所有的应用服务的工具。\n",
    "\n",
    "不过，还是那句话，docker的运用并不容易。\n",
    "\n",
    "首先要安装docker。\n",
    "\n",
    "然后还要理解docker大致是如何工作的。这个并不太容易。\n",
    "\n",
    "如果不做开发，也没有很多外部services需要使用，那么可以暂时不管它。前面说的已经足够用了。接下来，先记录下docker的基本概念，然后再来看看docker在python项目中的运用。\n",
    "\n",
    "### Introduction to docker\n",
    "\n",
    "如果需要完整的书籍资料，可以参考：[Docker — 从入门到实践](https://github.com/yeasy/docker_practice)。\n",
    "\n",
    "这小节内容就先主要参考[[译] Docker 的学习和应用](https://juejin.im/post/5d650a36f265da03c34c0bb4)。\n",
    "\n",
    "容器（Container）对于提高软件研发和数据存储的安全性、再生性，以及可扩展性都大有用途。Docker 就是一个在容器中研发、部署以及运行程序的平台。实际上，Docker 就是集装箱的同义词。为什么使用docker，参考[可能是把Docker的概念讲的最清楚的一篇文章](https://juejin.im/post/5b260ec26fb9a00e8e4b031a)，[[翻譯]看Docker如何幫助你成為高效資料科學家](https://medium.com/@alicialee/%E7%BF%BB%E8%AD%AF-%E7%9C%8Bdocker%E5%A6%82%E4%BD%95%E5%B9%AB%E5%8A%A9%E4%BD%A0%E6%88%90%E7%82%BA%E9%AB%98%E6%95%88%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8%E5%AE%B6-72f236166466)\n",
    "\n",
    "- Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 “这段代码在我机器上没问题啊” 这类问题；——一致的运行环境\n",
    "- 可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。——更快速的启动时间\n",
    "- 避免公用的服务器，资源会容易受到其他用户的影响。——隔离性\n",
    "- 善于处理集中爆发的服务器使用压力；——弹性伸缩，快速扩展\n",
    "- 可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。——迁移方便\n",
    "- 使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。——持续交付和部署\n",
    "\n",
    "另外对于python的开发或者数据分析者，Docker 是个必须要学习的内容。因为：\n",
    "\n",
    "- Reproducibility：能够重现你的研究工作是非常重要的，比如当你想把python建好的模型分享給你的同事时，只是給一份python套件清单或是几个txt是不够的，如果將你所用的开发环境封装起来，包含了你所使用的操作系统，编译器, drivers, 环境设定, 和相关的资料档案等一切能顺利运行程序的条件，交給你同事，让他能够快速重建一套相同的环境，是极好的。\n",
    "- Protability：当作业环境频繁改动时，可能会影响研究成果，比如刚开始很可能只在自己的PC上，但后来可能会转移到好的机器上，但这个转移可能会很麻烦，这时候Docker就能夠轻松地将研究资料, 函数库等打包并搬移到新环境。\n",
    "- 強化你的专业技能：有了Docker你就可以很放心的將你的研究成果或程序交給其他人來运行。\n",
    "\n",
    "关于docker，基本上都会从比喻开始：\n",
    "\n",
    "- docker作为一个容器，可以容纳事物，便携，提供清晰的接口 ，支持远程获取 。\n",
    "- 另一个比喻，是docker容器是一个活物的实例，Docker 容器就是 Docker 镜像的活体形态。\n",
    "- 将 Docker 容器看作是一个软件程序。从根本上来说，容器是一系列能计算比特的指令。\n",
    "\n",
    "然后，就要从虚拟机的概念开始谈起。虚拟机是 Docker 容器的前身。虚拟机也会分离应用和它的依赖。但是，Docker 容器需要的资源更少，更轻也更快，因此它要比虚拟机更加先进。根据[A Beginner-Friendly Introduction to Containers, VMs and Docker](https://www.freecodecamp.org/news/a-beginner-friendly-introduction-to-containers-vms-and-docker-79a9e3e119b/)，简单概括下虚拟机和容器的区别。\n",
    "\n",
    "虚拟机和容器在目标上是相似的，都是为了将应用和其依赖分离，以便于可以在任意地方运行于自包含单元中。他们都取消了对物理硬件的要求，更节省计算资源。两者的不同主要是架构方法不一样。\n",
    "\n",
    "虚拟机本质上是真实计算机的仿真，它像真实计算机一样执行程序。vm在使用hypervisor的物理机器上运行。hypervisor是是一段vm在其上运行的软件、固件或硬件。hypervisors是运行在物理机（主机）上的。主机提供包括RAM和CPU的虚拟机。RAM和CPU资源在虚拟机间可以分配。运行在主机上的VM也称为guest machine。guest machine包括应用和需要运行应用的东西，比如system binaries and libraries。还有它还携带了自己的整个虚拟化硬件堆栈，包括虚拟化的网络适配器、存储和CPU，这意味着它还拥有自己完整的guest operating system。总之形式如下：\n",
    "\n",
    "![](1_RKPXdVaqHRzmQ5RPBH_d-g.png)\n",
    "\n",
    "而容器不像VM那样能提供硬件的虚拟化，容器提供的是操作系统级别的虚拟化。容器看起来就像一个VM。例如，它们有专用的处理空间，可以作为根用户执行命令，有专用的网络接口和IP地址，允许自定义路由和iptable规则，可以挂载文件系统，等等。其最大的区别是**容器之间共享主机系统的内核**。容器只打包用户空间，而不像VM那样打包内核或虚拟硬件。每个容器都有自己的独立用户空间，允许多个容器在一台主机上运行。\n",
    "\n",
    "![](1_V5N9gJdnToIrgAgVJTtl_w.png)\n",
    "\n",
    "更深入的区别分析暂时不赘述了，目前先简单了解下足够了，后面有用得到的概念会再补充。\n",
    "\n",
    "接下来回到docker，看看其基本概念。\n",
    "\n",
    "- Docker镜像：docker的镜像是一个模子，用它来生成一样的多个容器。镜像包含 Dockerfile，库，以及需要运行的应用代码，所有这些绑定在一起组成镜像。\n",
    "- Dockfile：是一个包含了 Docker 如何构建镜像的指令的文件。\n",
    "    - Dockerfile 会指向一个可用于构建初始镜像层的基础镜像（比如使用广泛的官方基础镜像 python、ubuntu 和 alpine等）。\n",
    "    - 其他附加层将会根据 Dockerfile 中的指令，添加在基础镜像层的上面。例如，机器学习应用的 Dockerfile 将会通知 Docker 在中间层中添加 NumPy、Pandas 和 Scikit-learn。\n",
    "    - 最后，一个很薄（体积小）并且可写的层将会根据 Dockerfile 的代码添加在所有层的上方。\n",
    "- Docker Container：Docker 镜像加上命令 docker run image_name 将会从这个镜像中创建一个容器，并启动它。\n",
    "- Container 注册处：如果你想让其他人也可以使用你的镜像生成容器，你需要将镜像发送给容器注册处。Docker Hub 是最大的、也是人们默认的注册处。\n",
    "\n",
    "总结下，像做一款披萨一样。\n",
    "\n",
    "- 配方就是 Dockerfile。它告诉我们如何操作才能做好这款披萨。\n",
    "- 材料就是 Docker 的层。现在你已经有了披萨的面坯，酱料以及芝士了。\n",
    "- 将配方和原料的组合想象为一个一体化的披萨制作工具包。这就是 Docker 镜像。\n",
    "\n",
    "配方（Dockerfile）告诉了我们操作步骤。如下：\n",
    "\n",
    "- 披萨面坯是不能改的，就好比是基础的 ubuntu 父级镜像。它是底层，并且会最先被构建。\n",
    "- 然后还需要添加一些芝士。披萨的第二层就好比安装外部库 —— 例如 NumPy。\n",
    "- 然后你还可以撒上一些罗勒。罗勒就好比你写在文件里的代码，用来运行你的应用。\n",
    "\n",
    "接下来可以烤了：\n",
    "\n",
    "- 用来烤披萨的烤箱就好比是 Docker 平台。你将烤箱搬到你的家里，这样就可以用它来烹饪了。相似的，你把 Docker 安装到你的电脑里，这样就可以操作容器。\n",
    "- 你通过旋转旋钮来让烤箱开始工作。docker run image_name 指令就像是你的旋钮 —— 它可以创建并让容器开始工作。\n",
    "- 做好的披萨就好比是一个 Docker 容器。\n",
    "- 享用披萨就好比是使用你的应用。\n",
    "\n",
    "\n",
    "接下来就进入实操阶段，通过示例来学习docker配置python机器学习环境。\n",
    "\n",
    "### Python Docker Tutorials -- Run Python Versions in Docker: How to Try the Latest Python Release\n",
    "\n",
    "这部分主要参考了:[Python Docker Tutorials](https://realpython.com/tutorials/docker/)。\n",
    "\n",
    "Docker是Python开发者一个常用的开发工具。接下来看看如何将Docker加入到python开发工作流中，以用它来部署应用到本地或云端。\n",
    "\n",
    "这小节参考了:[Run Python Versions in Docker: How to Try the Latest Python Release](https://realpython.com/python-versions-docker/)\n",
    "\n",
    "先看看python的信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpython'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.implementation.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.implementation.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到本地用的是CPython3.7.4 。前面谈到过，用pipenv可以管理包，这里就看看使用Docker如何处理。第一步自然是安装Docker。可以参考：[Setting up your computer](https://docker-curriculum.com/#setting-up-your-computer)，[Docker — Beginner’s Guide — Part 1: Images & Containers](https://medium.com/codingthesmartway-com-blog/docker-beginners-guide-part-1-images-containers-6f3507fffc98)。\n",
    "\n",
    "对于开始使用docker的开发者来说，Docker Community Edition(CE) 足够了，上面的链接其实都是直接链接到官网文档的，直接按照官网做即可。首先 Uninstall old versions\n",
    "\n",
    "```Shell\n",
    "sudo apt-get remove docker docker-engine docker.io containerd runc\n",
    "```\n",
    "\n",
    "然后使用最常用的安装方式--Install using the repository，先设置REPOSITORY\n",
    "\n",
    "```Shell\n",
    "sudo apt-get update\n",
    "\n",
    "sudo apt-get install \\\n",
    "    apt-transport-https \\\n",
    "    ca-certificates \\\n",
    "    curl \\\n",
    "    gnupg-agent \\\n",
    "    software-properties-common\n",
    "    \n",
    "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n",
    "\n",
    "sudo apt-key fingerprint 0EBFCD88\n",
    "\n",
    "sudo add-apt-repository \\\n",
    "   \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\n",
    "   $(lsb_release -cs) \\\n",
    "   stable\"\n",
    "```\n",
    "\n",
    "然后可以安装docker-ce了。\n",
    "\n",
    "```Shell\n",
    "sudo apt-get update\n",
    "sudo apt-get install docker-ce docker-ce-cli containerd.io\n",
    "```\n",
    "\n",
    "接下来就可以看看自己是否安装成功了。\n",
    "\n",
    "```Shell\n",
    "sudo docker run hello-world\n",
    "```\n",
    "\n",
    "如果你是windows或者mac操作系统，可以参考这个：[Should You Install Docker with the Docker Toolbox or Docker for Mac / Windows?](https://nickjanetakis.com/blog/should-you-use-the-docker-toolbox-or-docker-for-mac-windows)\n",
    "\n",
    "下面可以看看如何使用Dockerfiles构建自己的镜像。Dockerfiles就是一个文本文件，它描述了如何设置一个docker image。比如：\n",
    "\n",
    "```Dockerfile\n",
    "FROM ubuntu\n",
    "RUN apt update && apt install -y cowsay\n",
    "CMD [\"/usr/games/cowsay\", \"Dockerfiles are cool!\"]\n",
    "```\n",
    "\n",
    "从上述代码可以看到，一个Dockerfile包含了一系列Docker命令。上述例子中三步分别是：\n",
    "\n",
    "1. 基于现有的docker image--Ubuntu创建该镜像\n",
    "2. 安装一个叫做cowsay的程序\n",
    "3. 准备一个命令，该命令在image被执行的时候用来运行cowsay\n",
    "\n",
    "为了使用这个dockerfile，要把它存储为一个名为Dockerfile的文本文件，注意是不需要文件扩展名的。这里我放到docker1文件夹下了。在该文件夹下打开终端执行（注意语句末有个 .）：\n",
    "\n",
    "```Shell\n",
    "sudo docker build -t cowsay .\n",
    "```\n",
    "\n",
    "该命令会给出很多输出，表明它正在构建镜像， -t cowsay参数是说会给镜像标记名称cowsay。最后的 . 是说指定当前文件夹为构建镜像的上下文。这个文件夹应该是包含Dockerfile的文件夹。\n",
    "\n",
    "执行完毕之后，发现并没有image文件，这是因为docker镜像存储在其他位置，可以通过下列命令查看：\n",
    "\n",
    "```Shell\n",
    "sudo docker info\n",
    "```\n",
    "\n",
    "根目录在/var/lib/docker，镜像就在这下面。接下来可以运行下这个镜像：\n",
    "\n",
    "```Shell\n",
    "sudo docker run --rm cowsay\n",
    "```\n",
    "\n",
    "--rm参数表示使用镜像后会清理掉容器。\n",
    "\n",
    "使用docker --help可以查看如何使用docker。\n",
    "\n",
    "现在看看如何在docker容器中运行python。Docker社区发布维护了所有python版本的dockerfile。\n",
    "\n",
    "首先，了解一下Docker社区--docker hub. 可以参考：[Docker — Beginner’s Guide — Part 1: Images & Containers](https://medium.com/codingthesmartway-com-blog/docker-beginners-guide-part-1-images-containers-6f3507fffc98)。 docker hub 有点类似于github，看上去是一个镜像市场，你可以在上面下载很多别人已经设置好的镜像。网站是[这里](https://hub.docker.com/)。如果你没有账号，那就注册一个。然后登录进去，就可以使用别人制作好的镜像了。\n",
    "\n",
    "当你运行一个来自Docker Hub的python镜像时，解释器会自动设置好，因此可以直接运行python库。上例子：在Python容器中运行下面的命令开始REPL（库）：\n",
    "\n",
    "```Shell\n",
    "sudo docker run -it --rm python:rc\n",
    "```\n",
    "\n",
    "该命令会直接从Docker Hub下载python:rc镜像，并启动一个容器且在容器中运行了python。-it 参数是交互式运行容器所需的参数。rc标签是release candidate的缩写，表示指向python最新版。这样就可以在刚才启动的python环境下运行python代码了。可以在刚才的环境下试试下面的代码：\n",
    "\n",
    "```Python\n",
    "import sys\n",
    "f\"{sys.version_info[:] = }\"\n",
    "```\n",
    "\n",
    "接下来，看看如何设置python环境。一个docker容器就是一个独立的环境。因此，不需要再添加一个python中用的虚拟环境到这个容器中。你可以直接运行pip来安装需要的包。使用dockerfile，修改容器来包含所需的外部包。比如下例，增加parse和realpython-reader到一个python3.7.5容器中：\n",
    "\n",
    "```Dockerfile\n",
    "FROM python:3.7.5-slim\n",
    "RUN python -m pip install \\\n",
    "        parse \\\n",
    "        realpython-reader\n",
    "```\n",
    "\n",
    "保存到Dockerfile，我放在docker2文件夹下了。  -slim标签表示dockerfile基于一个最小的Debian的Installation。即一个简洁版的Docker镜像。还有很多变种可以查看docker hub。\n",
    "\n",
    "虽然前面说了可以不用python虚拟环境，不过如果你有pipfile等，也是可以用的，不过要特别注意：每个RUN命令在一个单独的进程中运行，这意味着典型的虚拟环境激活在Dockerfile中不起作用。你需要通过设置VIRTUAL_ENV和PATH环境变量来手动激活虚拟环境。代码如下：\n",
    "\n",
    "```Dockerfile\n",
    "FROM python:3.7.5-slim\n",
    "\n",
    "# Set up and activate virtual environment\n",
    "ENV VIRTUAL_ENV \"/venv\"\n",
    "RUN python -m venv $VIRTUAL_ENV\n",
    "ENV PATH \"$VIRTUAL_ENV/bin:$PATH\"\n",
    "\n",
    "# Python commands run inside the virtual environment\n",
    "RUN python -m pip install \\\n",
    "        parse \\\n",
    "        realpython-reader\n",
    "```\n",
    "\n",
    "这部分可以进一步参考：[Elegantly activating a virtualenv in a Dockerfile](https://pythonspeed.com/articles/activate-virtualenv-dockerfile/)，这个稍后再说，先回到这边继续看看如何build以及run自己的dockerfile。使用下列代码：\n",
    "\n",
    "```Shell\n",
    "$ sudo docker build -t rp .\n",
    "[ ... Output clipped ... ]\n",
    "\n",
    "$ sudo docker run -it --rm rp\n",
    "```\n",
    "\n",
    "然后可以试试下面的代码：\n",
    "\n",
    "```Python\n",
    "import parse\n",
    "parse.__version__\n",
    "```\n",
    "\n",
    "也可以直接运行python命令：\n",
    "\n",
    "```Shell\n",
    "sudo docker run --rm rp realpython\n",
    "```\n",
    "\n",
    "这样就在rp容器中运行realpython命令了。\n",
    "\n",
    "了解了一些基本的python配置，接下来就关注下如何使用docker运行python脚本。看例子，docker3文件夹下创建一个headlines.py脚本。脚本首先下载Real Python最新版本，然后找到所有headlines，并打印到控制台，代码详见脚本。\n",
    "\n",
    "有两种方式在docker容器中运行脚本：\n",
    "\n",
    "1. 将本地目录作为卷挂载到Docker容器中\n",
    "2. 将脚本copy到docker容器中\n",
    "\n",
    "第一种方式在测试阶段尤其有用，因为当修改脚本的时候，不需要重新构建docker镜像。要挂在本地文件夹，使用-v参数：在docker3文件夹下执行：\n",
    "\n",
    "```Shell\n",
    "sudo docker run --rm -v /home/owen/Documents/Code/hydrus/1-basic-envir/docker3:/app rp python /app/headlines.py\n",
    "```\n",
    "\n",
    "其中，参数-v /home/owen/Documents/Code/hydrus/1-basic-envir/docker3:/app表示本地文件夹/home/owen/Documents/Code/hydrus/1-basic-envir/docker3应该被挂载到容器内的/app路径下（如果你使用本段代码，要改到自己的路径下）。然后就可以运行python命令：python /app/headlines.py 了。\n",
    "\n",
    "如果是部署脚本到别的机器，那么可能更想要copy脚本到容器中，这就需要向dockerfile中增加下列代码：\n",
    "\n",
    "```Dockerfile\n",
    "FROM python:3.7.5-slim\n",
    "WORKDIR /usr/src/app\n",
    "RUN python -m pip install \\\n",
    "        parse \\\n",
    "        realpython-reader\n",
    "COPY headlines.py .\n",
    "CMD [\"python\", \"headlines.py\"]\n",
    "```\n",
    "\n",
    "设置文件夹到容器中来控制命令在哪运行。直接在docker3文件夹下打开终端执行下列语句，看看效果：\n",
    "\n",
    "```Shell\n",
    "$ sudo docker build -t rp .\n",
    "[ ... Output clipped ... ]\n",
    "\n",
    "$ sudo docker run --rm rp\n",
    "Python Timers\n",
    "A Python Timer Class\n",
    "A Python Timer Context Manager\n",
    "A Python Timer Decorator\n",
    "The Python Timer Code\n",
    "Other Python Timer Functions\n",
    "Conclusion\n",
    "Resources\n",
    "```\n",
    "\n",
    "注意脚本在运行容器时运行了，因为我们已经在dockerfile中指定了CMD命令。关于更多的构建自己的dockerfile的方法可以参考[Python image description on Docker Hub](https://hub.docker.com/_/python/#how-to-use-this-image)\n",
    "\n",
    "到这里，已经了解了从docker hub上获取镜像及简单使用的方式了，不过还有许多可以使用的repo没说，python镜像的核心开发者可参见：[Quay.io](https://quay.io/repository/python-devs/ci-image)。使用非默认的库的镜像，要用全名，比如：\n",
    "\n",
    "```Shell\n",
    "sudo docker run -it --rm quay.io/python-devs/ci-image:master\n",
    "```\n",
    "\n",
    "该镜像会在容器中打开一个shell对话，在这个shell环境下，你可以显式地运行python：\n",
    "\n",
    "```Shell\n",
    "python3.9 -c \"import sys; print(sys.version_info)\"\n",
    "```\n",
    "\n",
    "可以看看该镜像中有哪些python版本可用\n",
    "\n",
    "```Shell\n",
    "ls /usr/local/bin/\n",
    "```\n",
    "\n",
    "这个镜像在测试代码在多个python版本上的可用性时尤其有用。\n",
    "\n",
    "上述记录可以帮助明确一些docker的基本概念，接下来就看看在一个典型的数据科学应用中docker的应用。\n",
    "\n",
    "### A Practical Introduction to Docker\n",
    "\n",
    "本节参考了[The Full Stack Data Scientist Part 2: A Practical Introduction to Docker](https://medium.com/applied-data-science/the-full-stack-data-scientist-part-2-a-practical-introduction-to-docker-1ea932c89b57)。\n",
    "\n",
    "Docker有很多优点，前面已经描述过了，这里就不再赘述，总之，它已经几乎成为了开发和部署应用中的必需品。Docker非常适合于持续集成/持续部署(CI/CD)工作流，是以敏捷、迭代的方式开发web/软件应用程序的首选工具。为了让数据科学项目从“概念验证”过渡到生产，我们必须能够无缝地集成业务技术堆栈的其余部分，而使用Docker可以帮助我们做到这一点。\n",
    "\n",
    "在数据科学项目中，一般有两个核心的组成：\n",
    "\n",
    "- a database \n",
    "- a machine running Python/R code\n",
    "\n",
    "本例子，就是为两个组件分别创建一个docker镜像。\n",
    "\n",
    "1. app: environment for running python code.\n",
    "2. db: an MSSQL server instance.\n",
    "\n",
    "结构如下图所示：\n",
    "\n",
    "![](1_q6hc5L3u0v3foNeswfsBJw.png)\n",
    "\n",
    "接下来下载代码：[code repository](https://github.com/chrisgschon/docker-for-ds)，这里也已经下载好了，在docker-for-ds-master文件夹。\n",
    "\n",
    "下面看看dockerfile是什么样的，不过在此之前，先简单了解下dockerfile究竟要怎么写。这块参考了：[docker_practice](https://github.com/yeasy/docker_practice)。\n",
    "\n",
    "先进一步了解下docker的基本概念--镜像和容器及如何定制镜像等。\n",
    "\n",
    "#### 定制镜像\n",
    "\n",
    "操作系统分为**内核和用户空间**，对于 Linux 而言，**内核启动后，会挂载 root 文件系统为其提供用户空间支持**。而 **Docker 镜像（Image）**，就**相当于是一个 root 文件系统**。比如官方镜像 ubuntu:18.04 就包含了完整的一套 Ubuntu 18.04 最小系统的 root 文件系统。\n",
    "\n",
    "Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。\n",
    "\n",
    "因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术（不用在意具体这个技术是啥），将其设计为**分层存储**的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是**由一组文件系统组成**，或者说，**由多层文件系统联合组成**。\n",
    "\n",
    "镜像构建时，会**一层层构建，前一层是后一层的基础**。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。\n",
    "\n",
    "分层存储的特征还使得镜像的复用、定制变的更为容易。甚至**可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像**。\n",
    "\n",
    "镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。**容器的实质是进程**，但与直接在宿主执行的进程不同，**容器进程运行于属于自己的独立的 *命名空间***。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。\n",
    "\n",
    "镜像使用的是**分层存储，容器**也是如此。每一个容器运行时，是**以镜像为基础层**，**在其上创建一个当前容器的存储层**，我们可以称这个为容器运行时读写而准备的存储层为 容器存储层。\n",
    "\n",
    "按照 Docker 最佳实践的要求，**容器不应该向其存储层内写入任何数据**，容器存储层要保持无状态化。**所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录**，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。\n",
    "\n",
    "**数据卷的生存周期独立于容器**，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。\n",
    "\n",
    "每次执行docker run的时候都会指定哪个镜像作为容器运行的基础。之前的例子中，使用的都来自于docker hub镜像。如果这些库不满足需求，那就需要定制镜像了。\n",
    "\n",
    "镜像是多层存储，每一层是在前一层的基础上进行的修改；而容器同样也是多层存储，是在以镜像为基础层，在其基础上加一层作为容器运行时的存储层。\n",
    "\n",
    "那么如何构建镜像？看例子。\n",
    "\n",
    "```Shell\n",
    "sudo docker run --name webserver -d -p 80:80 nginx\n",
    "```\n",
    "\n",
    "这条命令会用 nginx 镜像启动一个容器，命名为 webserver，并且映射了 80 端口，这样我们可以用浏览器去访问这个 nginx 服务器。\n",
    "\n",
    "如果是在 Linux 本机运行的 Docker，或者如果使用的是 Docker Desktop for Mac/Windows，那么可以直接访问：http://localhost 如果使用的是 Docker Toolbox，或者是在虚拟机、云服务器上安装的 Docker，则需要将 localhost 换为虚拟机地址或者实际云服务器地址。我这里是可以直接访问的，直接用浏览器访问，会看到默认的 Nginx 欢迎页面。\n",
    "\n",
    "假设我们非常不喜欢这个欢迎页面，我们希望改成欢迎 Docker 的文字，我们可以**使用 docker exec 命令进入容器，修改其内容**（我电脑上镜像的id是8dfb11c3d92c）。\n",
    "\n",
    "```Shell\n",
    "$ sudo docker exec -it webserver bash\n",
    "root@8dfb11c3d92c:/# echo '<h1>Hello, Docker!</h1>' > /usr/share/nginx/html/index.html\n",
    "root@8dfb11c3d92c:/# exit\n",
    "exit\n",
    "```\n",
    "\n",
    "上述命令是以交互式终端方式（-it参数）进入 webserver 容器，并执行了 bash 命令，也就是获得一个可操作的 Shell。\n",
    "\n",
    "然后，用 \\<h1>Hello, Docker!\\</h1> 覆盖了 /usr/share/nginx/html/index.html 的内容。\n",
    "\n",
    "刷新浏览器的话，会发现内容被改变了。\n",
    "\n",
    "修改了容器的文件，也就是**改动了容器的存储层**。我们可以通过 docker diff 命令看到具体的改动。\n",
    "\n",
    "```Shell\n",
    "$ sudo docker diff webserver\n",
    "C /root\n",
    "A /root/.bash_history\n",
    "C /run\n",
    "A /run/nginx.pid\n",
    "C /usr\n",
    "C /usr/share\n",
    "C /usr/share/nginx\n",
    "C /usr/share/nginx/html\n",
    "C /usr/share/nginx/html/index.html\n",
    "C /var\n",
    "C /var/cache\n",
    "C /var/cache/nginx\n",
    "A /var/cache/nginx/fastcgi_temp\n",
    "A /var/cache/nginx/proxy_temp\n",
    "A /var/cache/nginx/scgi_temp\n",
    "A /var/cache/nginx/uwsgi_temp\n",
    "A /var/cache/nginx/client_temp\n",
    "```\n",
    "\n",
    "现在我们定制好了变化，我们希望能将其保存下来形成镜像。当我们运行一个容器的时候（如果不使用卷的话），我们做的**任何文件修改都会被记录于容器存储层里**。 Docker 提供了一个 docker commit 命令，可以将容器的存储层保存下来成为镜像。换句话说，就是**在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像**。以后我们运行这个新镜像的时候，就会拥有原有容器最后的文件变化。\n",
    "\n",
    "```Shell\n",
    "sudo docker commit \\\n",
    "    --author \"Tao Wang <twang2218@gmail.com>\" \\\n",
    "    --message \"修改了默认网页\" \\\n",
    "    webserver \\\n",
    "    nginx:v2\n",
    "```\n",
    "\n",
    "--author 是指定修改的作者，而 --message 则是记录本次修改的内容。这点和 git 版本控制相似，不过这里这些信息可以省略留空。docker image ls查看新定制的镜像。\n",
    "\n",
    "```Shell\n",
    "sudo docker image ls nginx\n",
    "```\n",
    "\n",
    "新的镜像定制好后，我们可以来运行这个镜像。\n",
    "\n",
    "```Shell\n",
    "sudo docker run --name web2 -d -p 81:80 nginx:v2\n",
    "```\n",
    "\n",
    "这里我们命名为新的服务为 web2，并且映射到 81 端口。如果是 Docker Desktop for Mac/Windows 或 Linux 桌面的话，我们就可以直接访问 http://localhost:81 看到结果，其内容应该和之前修改后的 webserver 一样。\n",
    "\n",
    "至此，我们第一次完成了定制镜像，使用的是 docker commit 命令，手动操作给旧的镜像添加了新的一层，形成新的镜像，对镜像多层存储应该有了更直观的感觉。但是**实际环境中并不会这样使用！！！**。\n",
    "\n",
    "因为除了真正想要修改的 /usr/share/nginx/html/index.html 文件外，由于命令的执行，还有**很多文件被改动或添加了**。\n",
    "\n",
    "此外，使用 docker commit 意味着所有对镜像的操作都是**黑箱操作**，生成的镜像也被称为**黑箱镜像**，换句话说，就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像，别人根本无从得知。而且，即使是这个制作镜像的人，过一段时间后也无法记清具体在操作的。虽然 docker diff 或许可以告诉得到一些线索，但是远远不到可以确保生成一致镜像的地步。这种**黑箱镜像的维护工作是非常痛苦的**。\n",
    "\n",
    "而如果我们可以**把每一层修改、安装、构建、操作的命令都写入一个脚本**，用这个**脚本来构建、定制镜像**，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 **Dockerfile**。\n",
    "\n",
    "Dockerfile 是一个文本文件，其内包含了一条条的 **指令(Instruction)**，**每一条指令构建一层**，因此每一条指令的内容，就是描述该层应当如何构建。\n",
    "\n",
    "还以之前定制 nginx 镜像为例，这次使用 Dockerfile 来定制。\n",
    "\n",
    "```Shell\n",
    "mkdir mynginx\n",
    "cd mynginx\n",
    "touch Dockerfile\n",
    "```\n",
    "\n",
    "dockerfile内容为：\n",
    "\n",
    "```Dockerfile\n",
    "FROM nginx\n",
    "RUN echo '<h1>Hello, Docker!</h1>' > /usr/share/nginx/html/index.html\n",
    "```\n",
    "\n",
    "这个 Dockerfile 很简单，一共就两行。涉及到了两条指令，FROM 和 RUN。先看看这两条命令：\n",
    "\n",
    "所谓定制镜像，那一定是**以一个镜像为基础，在其上进行定制**。就像我们之前运行了一个 nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 **FROM 就是指定 基础镜像**，因此一个 Dockerfile 中 **FROM 是必备的指令，并且必须是第一条指令**。\n",
    "\n",
    "在 Docker Hub 上有非常多的高质量的官方镜像，有可以直接拿来使用的服务类的镜像，如 nginx、redis、mongo、mysql、httpd、php、tomcat 等；也有一些方便开发、构建、运行各种语言应用的镜像，如 node、openjdk、python、ruby、golang 等。可以在其中**寻找一个最符合我们最终目标的镜像为基础镜像进行定制**。\n",
    "\n",
    "如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的**操作系统镜像**，如 ubuntu、debian、centos、fedora、alpine 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。\n",
    "\n",
    "除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。\n",
    "\n",
    "RUN 指令是用来**执行命令行命令**的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种：\n",
    "\n",
    "- shell 格式：RUN <命令>，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 RUN 指令就是这种格式。\n",
    "- exec 格式：RUN [\"可执行文件\", \"参数1\", \"参数2\"]，这更像是函数调用中的格式。\n",
    "\n",
    "Dockerfile 中每一个指令都会建立一层，RUN 也不例外。每一个 RUN 的行为，就和刚才我们手工建立镜像的过程一样：**新建立一层，在其上执行这些命令，执行结束后，commit 这一层的修改，构成新的镜像**。因此不要像下面这么写：\n",
    "\n",
    "```Dockerfile\n",
    "FROM debian:stretch\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get install -y gcc libc6-dev make wget\n",
    "RUN wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\"\n",
    "RUN mkdir -p /usr/src/redis\n",
    "RUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1\n",
    "RUN make -C /usr/src/redis\n",
    "RUN make -C /usr/src/redis install\n",
    "```\n",
    "\n",
    "因为这种写法，创建了 7 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。 这是很多初学 Docker 的人常犯的一个错误。**Union FS 是有最大层数限制的，比如 AUFS，曾经是最大不得超过 42 层，现在是不得超过 127 层**。\n",
    "\n",
    "上面的 Dockerfile 正确的写法应该是这样：\n",
    "\n",
    "```Dockerfile\n",
    "FROM debian:stretch\n",
    "\n",
    "RUN buildDeps='gcc libc6-dev make wget' \\\n",
    "    && apt-get update \\\n",
    "    && apt-get install -y $buildDeps \\\n",
    "    && wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\" \\\n",
    "    && mkdir -p /usr/src/redis \\\n",
    "    && tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\\n",
    "    && make -C /usr/src/redis \\\n",
    "    && make -C /usr/src/redis install \\\n",
    "    && rm -rf /var/lib/apt/lists/* \\\n",
    "    && rm redis.tar.gz \\\n",
    "    && rm -r /usr/src/redis \\\n",
    "    && apt-get purge -y --auto-remove $buildDeps\n",
    "```\n",
    "\n",
    "首先，之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 对一一对应不同的命令，而是仅仅使用一个 RUN 指令，并使用 && 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这**并不是在写 Shell 脚本，而是在定义每一层该如何构建**。\n",
    "\n",
    "并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的**行尾添加 \\ 的命令换行**方式，以及**行首 # 进行注释**的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。\n",
    "\n",
    "此外，还可以看到这一组命令的**最后添加了清理工作的命令**，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。\n",
    "\n",
    "让我们再回到之前定制的 nginx 镜像的 Dockerfile 来。明白了这个 Dockerfile 的内容，那么让我们就来构建这个镜像吧。\n",
    "\n",
    "在 Dockerfile 文件所在目录下打开终端并执行：\n",
    "\n",
    "```Shell\n",
    "$ sudo docker build -t nginx:v3 .\n",
    "Sending build context to Docker daemon  3.584kB\n",
    "Step 1/2 : FROM nginx\n",
    " ---> f7bb5701a33c\n",
    "Step 2/2 : RUN echo '<h1>Hello, Docker!</h1>' > /usr/share/nginx/html/index.html\n",
    " ---> Running in bf3b35b7f880\n",
    "Removing intermediate container bf3b35b7f880\n",
    " ---> 2925eb04fada\n",
    "Successfully built 2925eb04fada\n",
    "Successfully tagged nginx:v3\n",
    "\n",
    "```\n",
    "\n",
    "从命令的输出结果中，我们可以清晰的看到镜像的构建过程。在 Step 2 中，如同我们之前所说的那样，RUN 指令启动了一个容器 bf3b35b7f880，执行了所要求的命令，并最后提交了这一层 2925eb04fada，随后删除了所用到的这个容器 bf3b35b7f880。\n",
    "\n",
    "docker build 命令进行镜像构建的格式为：docker build [选项] <上下文路径/URL/->\n",
    "\n",
    "在这里我们指定了最终镜像的名称 -t nginx:v3，构建成功后，我们可以像之前运行 nginx:v2 那样来运行这个镜像，其结果会和 nginx:v2 一样。\n",
    "\n",
    "那么上下文路径是什么呢？Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。如下图所示（参考[Docker Simplified: A Hands-On Guide for Absolute Beginners](https://www.freecodecamp.org/news/docker-simplified-96639a35ff36/)）\n",
    "\n",
    "![](1_MYX0ClbWoitxS0RNUVvj8A.png)\n",
    "\n",
    "Docker Engine 是 Docker 的核心组件之一，它是一个基于client-server的应用，包含三个主要组成部分：\n",
    "\n",
    "- **Server**：runs a daemon known as dockerd (Docker Daemon)，就是一个进程，负责创建、管理docker平台上的docker镜像，容器，网络，卷等\n",
    "- **REST API**：指定了应用如何和Server交互\n",
    "- **Client**：一个命令行接口command line interface（CLI），用户用这些命令来和docker交互。\n",
    "\n",
    "其中，REST API，又被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 docker 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 **C/S 设计**，让我们操作远程服务器的 Docker 引擎变得轻而易举。\n",
    "\n",
    "当我们进行镜像构建的时候，**并非所有定制都会通过 RUN 指令完成**，经常会**需要将一些本地文件复制进镜像**，比如通过 COPY 指令、ADD 指令等。而 **docker build 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的**。那么在这种客户端/服务端的架构中，**如何才能让服务端获得本地文件**呢？\n",
    "\n",
    "这就引入了上下文的概念。当**构建的时候**，用户会**指定构建镜像上下文的路径**，docker build 命令得知这个路径后，会**将路径下的所有内容打包，然后上传给 Docker 引擎**。这样 **Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件**。\n",
    "\n",
    "如果在 Dockerfile 中这么写：\n",
    "\n",
    "```Dockerfile\n",
    "COPY ./package.json /app/\n",
    "```\n",
    "\n",
    "这并不是要复制执行 docker build 命令所在的目录下的 package.json，也不是复制 Dockerfile 所在目录下的 package.json，而是复制 **上下文（context） 目录下的 package.json**。\n",
    "\n",
    "COPY 这类指令中的源文件的路径都是**相对路径**。这也是初学者经常会问的为什么 COPY ../package.json /app 或者 COPY /opt/xxxx /app 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们**复制到上下文目录中**去。\n",
    "\n",
    "所以，build语句那个.的作用就是在指定上下文的目录，docker build 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。\n",
    "\n",
    "观察 docker build 输出，我们其实已经看到了这个发送上下文的过程：\n",
    "\n",
    "```Shell\n",
    "$ sudo docker build -t nginx:v3 .\n",
    "Sending build context to Docker daemon  3.584kB\n",
    "...\n",
    "```\n",
    "\n",
    "理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 COPY /opt/xxxx /app 不工作后，于是干脆将 Dockerfile 放到了硬盘根目录去构建，结果发现 docker build 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 docker build 打包整个硬盘，这显然是使用错误。\n",
    "\n",
    "一般来说，应该会**将 Dockerfile 置于一个空目录下，或者项目根目录下**。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 .gitignore 一样的语法写一个 .dockerignore，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。\n",
    "\n",
    "在默认情况下，如果不额外指定 Dockerfile 的话，会将上下文目录下的名为 Dockerfile 的文件作为 Dockerfile。实际上 Dockerfile 的文件名并不要求必须为 Dockerfile，而且并不要求必须位于上下文目录中，比如可以用 -f ../Dockerfile.php 参数指定某个文件作为 Dockerfile。\n",
    "\n",
    "一般大家习惯性的会**使用默认的文件名 Dockerfile，以及会将其置于镜像构建上下文目录中**。\n",
    "\n",
    "那么接下来再看看Dockerfile其他一些指令的含义。\n",
    "\n",
    "#### Dockerfile 指令详解\n",
    "\n",
    "Dockerfile 功能很强大，它提供了十多个指令。这里先对几个前面见到过的命令做写阐述：\n",
    "\n",
    "##### COPY 复制文件\n",
    "\n",
    "格式：\n",
    "\n",
    "```Dockerfile\n",
    "COPY [--chown=<user>:<group>] <源路径>... <目标路径>\n",
    "COPY [--chown=<user>:<group>] [\"<源路径1>\",... \"<目标路径>\"]\n",
    "```\n",
    "\n",
    "两种格式，一种类似于命令行，一种类似于函数调用。\n",
    "\n",
    "COPY 指令将从**构建上下文目录中 <源路径> 的文件/目录**复制到**新的一层的镜像内的<目标路径> 位置**。比如：\n",
    "\n",
    "```Dockerfile\n",
    "COPY package.json /usr/src/app/\n",
    "```\n",
    "\n",
    "<源路径> 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则。\n",
    "\n",
    "<目标路径> 可以是**容器内的绝对路径**，也可以是**相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）**。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。\n",
    "\n",
    "还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。\n",
    "\n",
    "在使用该指令的时候还可以加上 --chown=\\<user>:\\<group> 选项来改变文件的所属用户及所属组。比如：\n",
    "\n",
    "```Dockerfile\n",
    "COPY --chown=55:mygroup files* /mydir/\n",
    "COPY --chown=bin files* /mydir/\n",
    "COPY --chown=1 files* /mydir/\n",
    "COPY --chown=10:11 files* /mydir/\n",
    "```\n",
    "\n",
    "##### ADD 更高级的复制文件\n",
    "\n",
    "ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。\n",
    "\n",
    "比如 **<源路径> 可以是一个 URL**，这种情况下，Docker 引擎会试图去**下载这个链接的文件放到 <目标路径> 去**。下载后的文件权限自动设置为 600，如果这并**不是想要的权限，那么还需要增加额外的一层 RUN 进行权限调整**，另外，如果**下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩**。所以**不如直接使用 RUN 指令，然后使用 wget 或者 curl 工具下载，处理权限、解压缩、然后清理无用文件更合理**。因此，**这个功能其实并不实用，而且不推荐使用**。所以就不再多废话了。\n",
    "\n",
    "##### CMD 容器启动命令\n",
    "\n",
    "CMD 指令的格式和 RUN 相似，也是两种格式：\n",
    "\n",
    "- shell 格式：CMD <命令>\n",
    "- exec 格式：CMD [\"可执行文件\", \"参数1\", \"参数2\"...]\n",
    "\n",
    "参数列表格式：CMD [\"参数1\", \"参数2\"...]。在指定了 ENTRYPOINT 指令后，用 CMD 指定具体的参数。\n",
    "\n",
    "容器就是进程。既然是进程，那么**在启动容器的时候，需要指定所运行的程序及参数**。**CMD 指令就是用于指定默认的容器主进程的启动命令的**。\n",
    "\n",
    "在运行时可以**指定新的命令来替代镜像设置中的这个默认命令**，比如，**ubuntu 镜像默认的 CMD 是 /bin/bash**，如果我们**直接 docker run -it ubuntu 的话，会直接进入 bash**。我们也可以在运行时指定运行别的命令，如 docker run -it ubuntu cat /etc/os-release。这就是用 cat /etc/os-release 命令替换了默认的 /bin/bash 命令了，输出了系统版本信息。\n",
    "\n",
    "在指令格式上，一般**推荐使用 exec 格式**，这类格式在解析时会被解析为 JSON 数组，因此**一定要使用双引号 \"**，而不要使用单引号。\n",
    "\n",
    "提到 CMD 就不得不提**容器中应用在前台执行和后台执行的问题**。这是初学者常出现的一个混淆。\n",
    "\n",
    "Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 systemd 去启动后台服务，**容器内没有后台服务的概念**。对于容器而言，其**启动程序就是容器应用进程**，**容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义**，从而退出，其它辅助进程不是它需要关心的东西。\n",
    "\n",
    "##### ENTRYPOINT入口点\n",
    "\n",
    "ENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式。\n",
    "\n",
    "ENTRYPOINT 的目的和 CMD 一样，都是在**指定容器启动程序及参数**。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 --entrypoint 来指定。\n",
    "\n",
    "当**指定了 ENTRYPOINT 后**，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 **CMD 的内容作为参数传给 ENTRYPOINT 指令**，换句话说实际执行时，将变为：\n",
    "\n",
    "```Dockerfile\n",
    "<ENTRYPOINT> \"<CMD>\"\n",
    "```\n",
    "\n",
    "有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种方式有什么好处么？看两个场景。\n",
    "\n",
    "场景一：让镜像变成像命令一样使用。\n",
    "\n",
    "假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 CMD 来实现：\n",
    "\n",
    "```Dockerfile\n",
    "FROM ubuntu:18.04\n",
    "RUN apt-get update \\\n",
    "    && apt-get install -y curl \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "CMD [ \"curl\", \"-s\", \"https://ip.cn\" ]\n",
    "```\n",
    "\n",
    "假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行：\n",
    "\n",
    "```Shell\n",
    "$ docker run myip\n",
    "当前 IP：61.148.226.66 来自：北京市 联通\n",
    "```\n",
    "\n",
    "这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？如果我们希望显示 HTTP 头信息，就需要加上 -i 参数。那么我们可以直接加 -i 参数给 docker run myip 么？\n",
    "\n",
    "```Shell\n",
    "$ docker run myip -i\n",
    "docker: Error response from daemon: invalid header field value \"oci runtime error: container_linux.go:247: starting container process caused \\\"exec: \\\\\\\"-i\\\\\\\": executable file not found in $PATH\\\"\\n\".\n",
    "```\n",
    "\n",
    "跟在**镜像名后面的是 command，运行时会替换 CMD 的默认值**。因此这里的 -i 替换了原来的 CMD，而不是添加在原来的 curl -s https://ip.cn 后面。而 -i 根本不是命令，所以自然找不到。\n",
    "\n",
    "如果我们希望加入 -i 这参数，我们就必须重新完整的输入这个命令：\n",
    "\n",
    "```Shell\n",
    "docker run myip curl -s https://ip.cn -i\n",
    "```\n",
    "\n",
    "这显然不是很好的解决方案，而使用 ENTRYPOINT 就可以解决这个问题。现在我们重新用 ENTRYPOINT 来实现这个镜像：\n",
    "\n",
    "```Dockerfile\n",
    "FROM ubuntu:18.04\n",
    "RUN apt-get update \\\n",
    "    && apt-get install -y curl \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "ENTRYPOINT [ \"curl\", \"-s\", \"https://ip.cn\" ]\n",
    "```\n",
    "\n",
    "再来尝试直接使用 docker run myip -i：\n",
    "\n",
    "```Shell\n",
    "$ docker run myip\n",
    "当前 IP：61.148.226.66 来自：北京市 联通\n",
    "\n",
    "$ docker run myip -i\n",
    "HTTP/1.1 200 OK\n",
    "Server: nginx/1.8.0\n",
    "Date: Tue, 22 Nov 2016 05:12:40 GMT\n",
    "Content-Type: text/html; charset=UTF-8\n",
    "Vary: Accept-Encoding\n",
    "X-Powered-By: PHP/5.6.24-1~dotdeb+7.1\n",
    "X-Cache: MISS from cache-2\n",
    "X-Cache-Lookup: MISS from cache-2:80\n",
    "X-Cache: MISS from proxy-2_6\n",
    "Transfer-Encoding: chunked\n",
    "Via: 1.1 cache-2:80, 1.1 proxy-2_6:8006\n",
    "Connection: keep-alive\n",
    "\n",
    "当前 IP：61.148.226.66 来自：北京市 联通\n",
    "```\n",
    "\n",
    "这次成功了。这是因为**当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl**，从而达到了我们预期的效果。\n",
    "\n",
    "场景二：应用运行前的准备工作\n",
    "\n",
    "启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。\n",
    "\n",
    "比如 mysql 类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的 mysql 服务器运行之前解决。\n",
    "\n",
    "此外，可能希望避免使用 root 用户去启动服务，从而提高安全性，而在启动服务前还需要以 root 身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 root 身份执行，方便调试等。\n",
    "\n",
    "这些准备工作是和容器 CMD 无关的，无论 CMD 为什么，都需要事先进行一个预处理的工作。这种情况下，可以**写一个脚本，然后放入 ENTRYPOINT 中去执行**，而这个脚本会将接到的参数（也就是 <CMD>）作为命令，在脚本最后执行。\n",
    "\n",
    "##### ENV 设置环境变量\n",
    "\n",
    "格式有两种：\n",
    "\n",
    "```Dockerfile\n",
    "ENV <key> <value>\n",
    "ENV <key1>=<value1> <key2>=<value2>...\n",
    "```\n",
    "\n",
    "这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。\n",
    "\n",
    "##### ARG 构建参数\n",
    "\n",
    "格式：ARG <参数名>[=<默认值>]\n",
    "\n",
    "构建参数和 ENV 的效果一样，都是**设置环境变量**。所不同的是，ARG 所设置的构建环境的环境变量，**在将来容器运行时是不会存在这些环境变量的**。但是不要因此就使用 ARG 保存密码之类的信息，因为 docker history 还是可以看到所有值的。\n",
    "\n",
    "Dockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 --build-arg <参数名>=<值> 来覆盖。\n",
    "\n",
    "##### VOLUME 定义匿名卷\n",
    "\n",
    "格式为：\n",
    "\n",
    "```Dockerfile\n",
    "VOLUME [\"<路径1>\", \"<路径2>\"...]\n",
    "VOLUME <路径>\n",
    "```\n",
    "\n",
    "容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中（稍后补充），为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。\n",
    "\n",
    "##### WORKDIR 指定工作目录\n",
    "\n",
    "使用 WORKDIR 指令可以来**指定工作目录**（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。\n",
    "\n",
    "之前提到一些初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误：\n",
    "\n",
    "```Dockerfile\n",
    "RUN cd /app\n",
    "RUN echo \"hello\" > world.txt\n",
    "```\n",
    "\n",
    "如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 /app/world.txt 文件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而**在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器**。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。\n",
    "\n",
    "因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令。\n",
    "\n",
    "#### Dockerfile 多阶段构建\n",
    "\n",
    "Docker 17.05 版本之前，我们构建 Docker 镜像时，通常会采用两种方式：\n",
    "\n",
    "- 全部放入一个 Dockerfile：将所有的构建过程编包含在一个 Dockerfile 中，包括项目及其依赖库的编译、测试、打包等流程，这里可能会带来的一些问题：镜像层次多，镜像体积较大，部署时间变长；源代码存在泄露的风险。\n",
    "- 分散到多个 Dockerfile：事先在一个 Dockerfile 将项目及其依赖库编译测试打包好后，再将其拷贝到运行环境中，这种方式需要我们编写两个 Dockerfile 和一些编译脚本才能将其两个阶段自动整合起来，这种方式虽然可以很好地规避第一种方式存在的风险，但明显部署过程较复杂。\n",
    "\n",
    "Docker v17.05 开始支持**多阶段构建 (multistage builds)**。使用多阶段构建我们就可以很容易解决前面提到的问题，并且只需要编写一个 Dockerfile。\n",
    "\n",
    "#### 数据管理\n",
    "\n",
    "前面有提到volume，这里再进一步补充。\n",
    "\n",
    "![](types-of-mounts.png)\n",
    "\n",
    "如何在 Docker 内部以及容器之间管理数据？之前也已经提到过了，在容器中管理数据主要有两种方式：\n",
    "\n",
    "- 数据卷（Volumes）\n",
    "- 挂载主机目录 (Bind mounts)\n",
    "\n",
    "##### 数据卷\n",
    "\n",
    "数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：\n",
    "\n",
    "- 数据卷 可以在容器之间共享和重用\n",
    "- 对 数据卷 的修改会立马生效\n",
    "- 对 数据卷 的更新，不会影响镜像\n",
    "- 数据卷 默认会一直存在，即使容器被删除\n",
    "\n",
    "数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会隐藏掉，能显示看的是挂载的 数据卷。\n",
    "\n",
    "使用下面语句可以创建一个数据卷\n",
    "\n",
    "```Shell\n",
    "sudo docker volume create my-vol\n",
    "```\n",
    "\n",
    "```Shell\n",
    "$ sudo  docker volume ls\n",
    "DRIVER              VOLUME NAME\n",
    "local               my-vol\n",
    "```\n",
    "\n",
    "在主机里使用以下命令可以查看指定 数据卷 的信息\n",
    "\n",
    "\n",
    "```Shell\n",
    "sudo docker volume inspect my-vol\n",
    "```\n",
    "\n",
    "在用 docker run 命令的时候，使用 --mount 标记来将 数据卷 挂载到容器里。在一次 docker run 中可以挂载多个 数据卷。\n",
    "\n",
    "下面创建一个名为 web 的容器，并加载一个 数据卷 到容器的 /webapp 目录。\n",
    "\n",
    "```Shell\n",
    "sudo docker run -d -P \\\n",
    "    --name web \\\n",
    "    --mount source=my-vol,target=/webapp \\\n",
    "    training/webapp \\\n",
    "    python app.py\n",
    "```\n",
    "\n",
    "在主机里使用以下命令可以查看 web 容器的信息\n",
    "\n",
    "```Shell\n",
    "sudo docker inspect web\n",
    "```\n",
    "\n",
    "数据卷 信息在 \"Mounts\" Key 下面.\n",
    "\n",
    "数据卷 是被设计用来**持久化数据的**，它的**生命周期独立于容器**，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。\n",
    "\n",
    "删除数据卷命令：\n",
    "\n",
    "```Shell\n",
    "sudo docker volume rm my-vol\n",
    "```\n",
    "\n",
    "##### 挂载主机目录\n",
    "\n",
    "使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。\n",
    "\n",
    "```Shell\n",
    "docker run -d -P \\\n",
    "    --name web \\\n",
    "    # -v /src/webapp:/opt/webapp \\\n",
    "    --mount type=bind,source=/src/webapp,target=/opt/webapp \\\n",
    "    training/webapp \\\n",
    "    python app.py\n",
    "```\n",
    "\n",
    "上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，以前使用 -v 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹，现在使用 --mount 参数时如果本地目录不存在，Docker 会报错。\n",
    "\n",
    "#### Docker compose\n",
    "\n",
    "前面说道数据科学项目很多是有两个核心组件：一个数据库和一个使用python代码的机器。那么不同的docker容器之间如何交互呢？这就要用到Docker Compose了。Docker Compose 是 Docker 官方编排（Orchestration）项目之一，**负责快速的部署分布式应用**。\n",
    "\n",
    "Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。它允许用户通过**一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目**（project）。\n",
    "\n",
    "接下来，从安装开始。Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。可以参考官方文档：[Install Docker Compose](https://docs.docker.com/compose/install/)，这里以linux下安装为例子，使用二进制包快速安装，两行代码：\n",
    "\n",
    "```Shell\n",
    "sudo curl -L \"https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n",
    "sudo chmod +x /usr/local/bin/docker-compose\n",
    "```\n",
    "\n",
    "安装之后，就看看如何使用。\n",
    "\n",
    "首先是，Compose 中有两个重要的概念：\n",
    "\n",
    "- 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。\n",
    "- 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。\n",
    "\n",
    "Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。一个**项目可以由多个服务（容器）关联而成**，**Compose 面向项目进行管理**。\n",
    "\n",
    "接下来先以以个web应用为例子，后面再回到数据科学的这个例子上来。用 Python 来建立一个能够记录页面访问次数的 web 网站。\n",
    "\n",
    "新建一个文件夹docker-compose，在目录下有一个app.py文件，代码详见文件。\n",
    "\n",
    "然后编写Dockerfile 文件，内容详见文件。\n",
    "\n",
    "然后编写 docker-compose.yml 文件，这个是 Compose 使用的主模板文件。详见文件。\n",
    "\n",
    "接下来在docker-compose文件夹下打开终端，运行compose 项目：\n",
    "\n",
    "```Shell\n",
    "sudo docker-compose up\n",
    "```\n",
    "\n",
    "此时访问本地 5000 端口: http://localhost:5000/ ，每次刷新页面，计数就会加 1。\n",
    "\n",
    "接下来，对compose命令做一些说明。\n",
    "\n",
    "对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，**命令对象将是项目**，这意味着项目中所有的服务都会受到命令影响。\n",
    "\n",
    "docker-compose 命令的基本的使用格式是\n",
    "\n",
    "```Shell\n",
    "sudo docker-compose [-f=<arg>...] [options] [COMMAND] [ARGS...]\n",
    "```\n",
    "\n",
    "命令选项:\n",
    "\n",
    "- -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。\n",
    "- -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。\n",
    "- --x-networking 使用 Docker 的可拔插网络后端特性\n",
    "- --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge\n",
    "- --verbose 输出更多调试信息。\n",
    "- -v, --version 打印版本并退出。\n",
    "\n",
    "命令使用说明（这里仅简单记录下作用）:\n",
    "\n",
    "- build: 构建（重新构建）项目中的服务容器\n",
    "- config：验证 Compose 文件格式是否正确\n",
    "- down：停止 up 命令所启动的容器，并移除网络\n",
    "- exec：进入指定的容器。\n",
    "- help：获得命令帮助。\n",
    "- images：列出 Compose 文件中包含的镜像。\n",
    "- kill：通过发送 SIGKILL 信号来强制停止服务容器。\n",
    "- logs：查看服务容器的输出。\n",
    "- pause：暂停一个服务容器。\n",
    "- port：打印某个容器端口所映射的公共端口。\n",
    "- ps：列出项目中目前的所有容器。\n",
    "- pull：拉取服务依赖的镜像。\n",
    "- push：推送服务依赖的镜像到 Docker 镜像仓库。\n",
    "- restart：重启项目中的服务。\n",
    "- rm：删除所有（停止状态的）服务容器。\n",
    "- run：在指定服务上执行一个命令。\n",
    "- scale：设置指定服务运行的容器个数。\n",
    "- start：启动已经存在的服务容器。\n",
    "- stop：停止已经处于运行状态的容器，但不删除它。\n",
    "- top：查看各个服务容器内运行的进程。\n",
    "- unpause：恢复处于暂停状态中的服务。\n",
    "- up：尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。大部分时候都可以直接通过该命令来启动一个项目。\n",
    "- version：打印版本信息。\n",
    "\n",
    "最后介绍compose部分，简单看看compose模板文件。\n",
    "\n",
    "模板文件是**使用 Compose 的核心**，涉及到的指令关键字也比较多。但不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。\n",
    "\n",
    "默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。\n",
    "\n",
    "到这里暂告一段落，回到 https://medium.com/applied-data-science/the-full-stack-data-scientist-part-2-a-practical-introduction-to-docker-1ea932c89b57\n",
    "\n",
    "现在可以很容易地了解到app/Dockerfile内的语句都是做什么的，并且也可以知道，blog作者的写法并不好，因为执行的RUN太多了，没必要搞这么多层。这部分可以修改下，不过这样也没太大影响。\n",
    "\n",
    "然后也可以简单地了解到compose.yml 文件的内容，该文件定义了项目下两个镜像，一个是app，一个是db。\n",
    "\n",
    "```docker-compose.yml\n",
    "version: '3'\n",
    "services:\n",
    "  app:\n",
    "    build:\n",
    "      context: ./app\n",
    "      dockerfile: Dockerfile\n",
    "    volumes:\n",
    "      - \"./app/code/:/code/\"\n",
    "    ports:\n",
    "      - 8888:8888\n",
    "    depends_on:\n",
    "      - db\n",
    "    tty: true\n",
    "    environment:\n",
    "      DB_ENGINE: sql_server.pyodbc\n",
    "      DB_NAME: master\n",
    "      DB_SERVER: host.docker.internal\n",
    "      DB_PORT: 1433\n",
    "      DB_DRIVER: \"ODBC Driver 17 for SQL Server\"\n",
    "      DB_USER: sa\n",
    "      DB_PWD: blogPWD123!\n",
    "      \n",
    "    command: /bin/bash\n",
    "\n",
    "  db:\n",
    "    image: microsoft/mssql-server-linux:2017-CU9\n",
    "    ports:\n",
    "      - 1433:1433\n",
    "    environment:\n",
    "      SA_PASSWORD: blogPWD123!\n",
    "      ACCEPT_EULA: Y\n",
    "```\n",
    "\n",
    "其中，app镜像指定了以下内容：\n",
    "\n",
    "- build — where to find the Dockerfile.\n",
    "- volumes — tells the app to edit code on our host file system when edited on app and vice versa.\n",
    "- ports — map the ports from the container to the host. Allows us to access jupyter.\n",
    "- depends_on — tells app to depend on a running instance of db, so db will be spun up first.\n",
    "- tty — setting as true means we can interact with the container (i.e. open a bash shell)\n",
    "- environment — set environment variables. These will allow us to easily set up a connection to our DB.\n",
    "- command — set the default command on running of the container.\n",
    "\n",
    "对于db，则指定了：\n",
    "\n",
    "- image — tells docker which image to pull from Docker hub.\n",
    "- ports — map port to host machine, allows access from e.g. database management system.\n",
    "- environment — set up password and accept the EULA (end user license agreement)\n",
    "\n",
    "在项目中运行docker-compose up -d 可以试试，本文已经很长了，这里就暂时到此为止了，这个示例就不在此演示了，后续如果要用到docker的话，在实际项目中再操作了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
