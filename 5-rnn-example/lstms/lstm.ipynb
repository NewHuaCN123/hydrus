{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM实践\n",
    "\n",
    "循环神经网络的变种LSTM模型也有很多种结构，从常规的lstm，到各类复杂结构，这里根据实际使用情况，以pytorch为主，也会有tf2的例子，逐步记录。\n",
    "\n",
    "## vanilla lstm\n",
    "\n",
    "常规的lstm模型。\n",
    "\n",
    "### LSTM in Torch\n",
    "\n",
    "在之前了解过基本神经网络构建的基础上，现在来讨论循环神经网络的使用。\n",
    "\n",
    "pytorch中，LSTM类继承自RNNBase类，RNNBase类继承自Module类，Module类是pytorch中完成一定网络功能的基类，可以通过继承该类定义自己的神经网络。自己实现神经网络时，一般要重写其forward方法。\n",
    "\n",
    "Module实现了__call__方法，这意味着其可被当做可调用方法使用。比如下面有用到lstm()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"一个简单的pytorch的lstm模型的示例\"\"\"\n",
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd  # torch中自动计算梯度模块\n",
    "import torch.nn as nn             # 神经网络模块\n",
    "import torch.nn.functional as F   # 神经网络模块中的常用功能\n",
    "import torch.optim as optim       # 模型优化器模块\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "lstm = nn.LSTM(3, 3)\n",
    "# 生成一个长度为5，每一个元素为1*3的序列作为输入，这里的数字3对应于上句中第一个3\n",
    "inputs = [autograd.Variable(torch.randn((1, 3))) for _ in range(5)]\n",
    "\n",
    "# 设置隐藏层维度，初始化隐藏层的数据。hidden变量是一个元组，其第一个元素是LSTM隐藏层输出，另一个元素维护隐藏层的状态。\n",
    "# torch.rand(1,1,3)就是生成了一个维度为(1,1,3)的以一定高斯分布生成的张量\n",
    "hidden = (autograd.Variable(torch.randn(1, 1, 3)),\n",
    "          autograd.Variable(torch.randn((1, 1, 3))))\n",
    "\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    print(out)\n",
    "    print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"代码来自博客https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of\n",
    "-household-power-consumption/ \"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# fill missing values with a value at the same time one day ago\n",
    "def fill_missing(values):\n",
    "    one_day = 60 * 24\n",
    "    for row in range(values.shape[0]):\n",
    "        for col in range(values.shape[1]):\n",
    "            if np.isnan(values[row, col]):\n",
    "                values[row, col] = values[row - one_day, col]\n",
    "\n",
    "\n",
    "# load all data\n",
    "dataset = pd.read_csv('../data/household_power_consumption.txt', sep=';', header=0, low_memory=False,\n",
    "                      infer_datetime_format=True, parse_dates={'datetime': [0, 1]}, index_col=['datetime'])\n",
    "\n",
    "# mark all missing values\n",
    "dataset.replace('?', np.nan, inplace=True)\n",
    "# make dataset numeric\n",
    "dataset = dataset.astype('float32')\n",
    "# fill missing\n",
    "fill_missing(dataset.values)\n",
    "\n",
    "# add a column for for the remainder of sub metering\n",
    "values = dataset.values\n",
    "dataset['sub_metering_4'] = (values[:, 0] * 1000 / 60) - (values[:, 4] + values[:, 5] + values[:, 6])\n",
    "\n",
    "# save updated dataset\n",
    "dataset.to_csv('../data/household_power_consumption.csv')\n",
    "\n",
    "# resample minute data to total for each day\n",
    "# load the new file\n",
    "dataset = pd.read_csv('../data/household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'],\n",
    "                      index_col=['datetime'])\n",
    "# resample data to daily\n",
    "daily_groups = dataset.resample('D')\n",
    "daily_data = daily_groups.sum()\n",
    "# summarize\n",
    "print(daily_data.shape)\n",
    "print(daily_data.head())\n",
    "# save\n",
    "daily_data.to_csv('../data/household_power_consumption_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate multi-step lstm\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "    # split into standard weeks\n",
    "    train, test = data[1:-328], data[-328:-6]\n",
    "    # restructure into windows of weekly data\n",
    "    train = array(split(train, len(train) / 7))\n",
    "    test = array(split(test, len(test) / 7))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col]) ** 2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores\n",
    "\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "\n",
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=7):\n",
    "    # flatten data\n",
    "    data = train.reshape((train.shape[0] * train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end < len(data):\n",
    "            x_input = data[in_start:in_end, 0]\n",
    "            x_input = x_input.reshape((len(x_input), 1))\n",
    "            X.append(x_input)\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "    return array(X), array(y)\n",
    "\n",
    "\n",
    "# train the model\n",
    "def build_model(train, n_input):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(train, n_input)\n",
    "    # define parameters\n",
    "    verbose, epochs, batch_size = 1, 70, 16\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit network\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model\n",
    "\n",
    "\n",
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "    # flatten data\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0] * data.shape[1], data.shape[2]))\n",
    "    # retrieve last observations for input data\n",
    "    input_x = data[-n_input:, 0]\n",
    "    # reshape into [1, n_input, 1]\n",
    "    input_x = input_x.reshape((1, len(input_x), 1))\n",
    "    # forecast the next week\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    # we only want the vector forecast\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "    # fit model\n",
    "    model = build_model(train, n_input)\n",
    "    # history is a list of weekly data\n",
    "    history = [x for x in train]\n",
    "    # walk-forward validation over each week\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict the week\n",
    "        yhat_sequence = forecast(model, history, n_input)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)\n",
    "        # get real observation and add to history for predicting the next week\n",
    "        history.append(test[i, :])\n",
    "    # evaluate predictions days for each week\n",
    "    predictions = array(predictions)\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    return score, scores\n",
    "\n",
    "\n",
    "# load the new file\n",
    "dataset = read_csv('../data/household_power_consumption_days.csv', header=0, infer_datetime_format=True,\n",
    "                   parse_dates=['datetime'], index_col=['datetime'])\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# evaluate model and get scores\n",
    "n_input = 7\n",
    "score, scores = evaluate_model(train, test, n_input)\n",
    "# summarize scores\n",
    "summarize_scores('lstm', score, scores)\n",
    "# plot scores\n",
    "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "pyplot.plot(days, scores, marker='o', label='lstm')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacked lstm\n",
    "\n",
    "先对stacked lstm有个基本认识，参考：[Single Layer & Multi-layer Long Short-Term Memory (LSTM) Model with Intermediate Variables for Weather Forecasting](https://www.sciencedirect.com/science/article/pii/S187705091831439X)，一个典型的stacked lstm结构是这样的：\n",
    "\n",
    "![](Picture9.png)\n",
    "\n",
    "接下来参考[Stacked Long Short-Term Memory Networks](https://machinelearningmastery.com/stacked-long-short-term-memory-networks/)记录一些基本内容。\n",
    "\n",
    "原始的lstm就是由一个LSTM隐含层和一个标准前向输出层组成。 Stacked LSTM 是对该模型的扩充，它有多个LSTM隐含层，每层有多个记忆单元。\n",
    "\n",
    "### 为什么要增加深度\n",
    "\n",
    "神经网络的深度通常被认为是该方法在一系列具有挑战性的预测问题上取得成功的原因。更多的隐含层能让神经网络更深。更深的隐含层目前被认为能从之前的层中重新组合学习到的特征并创建新的更高层次的抽象特征。比如从线到面到体。\n",
    "\n",
    "一个足够深的神经网络结构能用来估计大部分函数。增加网络的深度提供了一种需要更少的神经元和更快的训练的解决方案。因此，增加深度是一种典型的优化方式。\n",
    "\n",
    "### Stacked LSTM Architecture\n",
    "\n",
    "因为LSTM是作用于序列数据，这意味着随着时间推移，层数的增加增加了输入观察的抽象级别。实际上就是将观察结果随时间分块或在不同的时间尺度上表示问题。\n",
    "\n",
    "引用一段话：\n",
    "\n",
    "\" ... building a deep RNN by stacking multiple recurrent hidden states on top of each other. This approach potentially allows the hidden state at each level to operate at different timescale\"\n",
    "\n",
    "— [How to Construct Deep Recurrent Neural Networks, 2013](https://arxiv.org/abs/1312.6026)\n",
    "\n",
    "在一些研究中，LSTM的深度比一个给定层的memory cells的个数对模型来说更重要。Stacked LSTMs 现在已经是序列预测问题的一种较稳定的技术。一个Stacked LSTM模型可以由一个LSTM模型和多个LSTM层构成。如下图所示，上面的LSTM层不输出一个值，而是输出一个序列到下一层LSTM。具体来说，每个输入时间步一个输出，而不是所有输入时间步一个输出。\n",
    "\n",
    "### Implement Stacked LSTMs in Keras\n",
    "\n",
    "在Keras中可以很容易的创建Stacked LSTM，每个LSTM memory cell 需要一个3D输入，当LSTM处理一个时间步长的输入序列时，每个存储单元将以2D数组的形式输出整个序列的单个值。\n",
    "\n",
    "首先是一个单层的LSTM的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-25776a27f53e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example of one output for whole sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# define model where LSTM is also output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Example of one output for whole sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "# define model where LSTM is also output layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(3,1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# input time steps\n",
    "data = array([0.1, 0.2, 0.3]).reshape((1,3,1))\n",
    "# make and show prediction\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到输入数据有3个值。运行例子输出一个值，2D数组形式。\n",
    "\n",
    "为了堆叠LSTM层，需要修改LSTM层输出一个3D的数组作为下一层的输入。设置return_sequences=True，它就会输出一个序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of one output for each input time step\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "# define model where LSTM is also output layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, return_sequences=True, input_shape=(3,1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# input time steps\n",
    "data = array([0.1, 0.2, 0.3]).reshape((1,3,1))\n",
    "# make and show prediction\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后就可以增加LSTM层了。比如：\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(LSTM(..., return_sequences=True, input_shape=(...)))\n",
    "model.add(LSTM(...))\n",
    "model.add(Dense(...))\n",
    "```\n",
    "\n",
    "或者更多层：\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(LSTM(..., return_sequences=True, input_shape=(...)))\n",
    "model.add(LSTM(..., return_sequences=True))\n",
    "model.add(LSTM(..., return_sequences=True))\n",
    "model.add(LSTM(...))\n",
    "model.add(Dense(...))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
