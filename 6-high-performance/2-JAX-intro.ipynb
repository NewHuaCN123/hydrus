{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b603dab5-e4b6-4c1f-9963-6ff8c1baf6ee",
   "metadata": {},
   "source": [
    "# Jax 简介\n",
    "\n",
    "本文目的主要是简单了解JAX的基本情况。\n",
    "\n",
    "JAX的安装暂时还没有 PyTorch，Tensorflow那么方便，还需要自己手动安装好 CUDA 和 CuDNN 才能支持GPU 运算，由于本repo暂时在笔记本电脑上学习，所以暂时只安装CPU版本。\n",
    "\n",
    "参考:\n",
    "\n",
    "- [JAX Quickstart](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html)\n",
    "- [Introduction to JAX: Platform for Accelerated Machine Learning Research](https://www.technology.org/2020/07/12/introduction-to-jax-platform-for-accelerated-machine-learning-research/)\n",
    "- [Using JAX to accelerate our research](https://deepmind.com/blog/article/using-jax-to-accelerate-our-research)\n",
    "- [Getting started with JAX (MLPs, CNNs & RNNs)](https://roberttlange.github.io/posts/2020/03/blog-post-10/)\n",
    "\n",
    "**JAX is NumPy on the CPU, GPU, and TPU, with great automatic differentiation for high-performance machine learning research.**\n",
    "\n",
    "JAX是一个基于Numpy的，有着优秀自动微分计算能力的高性能机器学习研究库。\n",
    "\n",
    "使用它的 Autograd，JAX 能够自动微分 native Python和 NumPy代码。可以说是非常（优）秀了。它能在Python的大部分功能（包括循环，if，递归和闭包）上进行微分运算，还能计算微分的微分。它支持反向模式和正向模式微分，并且两者可以任意组合为任意顺序。\n",
    "\n",
    "JAX能使用 XLA 在诸如GPU和TPU的加速器上编译和运行NumPy代码。默认情况下，编译是在后台进行的，库调用得到及时的编译和执行。但是JAX允许使用单函数API，即时将自己的Python函数编译为XLA优化的内核。编译和自动微分可以任意组合，因此无需离开Python即可表达复杂的算法并获得最佳性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b1accb-df0b-42db-a969-55b99297259c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jax'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a48882b4a504>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jax'"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a8c07-1f58-4b0d-872f-fd74faf7fd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
